{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AJjv8DcPP4T9"
      },
      "outputs": [],
      "source": [
        "# =========================================================================\n",
        "# === NOTEBOOK CONFIGURATION ===\n",
        "# Set this to False to quickly load the best parameters for the autoencoder.\n",
        "# Set this to True to run a full Optuna study to find new best parameters.\n",
        "# RUN_FULL_OPTUNA_STUDY = True\n",
        "# ========================================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJXX-JUSKdp3",
        "outputId": "c7e9c67c-acae-46d7-eb65-4bb10ceb62d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.16.5)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.43)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna\n",
            "Successfully installed colorlog-6.9.0 optuna-4.5.0\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (5.24.1)\n",
            "Collecting plotly\n",
            "  Downloading plotly-6.3.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: narwhals>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from plotly) (2.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from plotly) (25.0)\n",
            "Downloading plotly-6.3.0-py3-none-any.whl (9.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: plotly\n",
            "  Attempting uninstall: plotly\n",
            "    Found existing installation: plotly 5.24.1\n",
            "    Uninstalling plotly-5.24.1:\n",
            "      Successfully uninstalled plotly-5.24.1\n",
            "Successfully installed plotly-6.3.0\n",
            "Collecting kaleido\n",
            "  Downloading kaleido-1.1.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting choreographer>=1.0.10 (from kaleido)\n",
            "  Downloading choreographer-1.1.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting logistro>=1.0.8 (from kaleido)\n",
            "  Downloading logistro-1.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: orjson>=3.10.15 in /usr/local/lib/python3.12/dist-packages (from kaleido) (3.11.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kaleido) (25.0)\n",
            "Collecting pytest-timeout>=2.4.0 (from kaleido)\n",
            "  Downloading pytest_timeout-2.4.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: simplejson>=3.19.3 in /usr/local/lib/python3.12/dist-packages (from choreographer>=1.0.10->kaleido) (3.20.1)\n",
            "Requirement already satisfied: pytest>=7.0.0 in /usr/local/lib/python3.12/dist-packages (from pytest-timeout>=2.4.0->kaleido) (8.4.2)\n",
            "Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.12/dist-packages (from pytest>=7.0.0->pytest-timeout>=2.4.0->kaleido) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.12/dist-packages (from pytest>=7.0.0->pytest-timeout>=2.4.0->kaleido) (1.6.0)\n",
            "Requirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from pytest>=7.0.0->pytest-timeout>=2.4.0->kaleido) (2.19.2)\n",
            "Downloading kaleido-1.1.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading choreographer-1.1.1-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.3/52.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading logistro-1.1.0-py3-none-any.whl (7.9 kB)\n",
            "Downloading pytest_timeout-2.4.0-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: logistro, pytest-timeout, choreographer, kaleido\n",
            "Successfully installed choreographer-1.1.1 kaleido-1.1.0 logistro-1.1.0 pytest-timeout-2.4.0\n",
            "\n",
            "Plotly will install a copy of Google Chrome to be used for generating static images of plots.\n",
            "Chrome will be installed at: None\n",
            "Do you want to proceed? [y/n] y\n",
            "Installing Chrome for Plotly...\n",
            "Chrome installed successfully.\n",
            "The Chrome executable is now located at: /usr/local/lib/python3.12/dist-packages/choreographer/cli/browser_exe/chrome-linux64/chrome\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install -U optuna\n",
        "!pip install -U plotly\n",
        "!pip install -U kaleido\n",
        "!plotly_get_chrome\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import gzip\n",
        "import json\n",
        "import io\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import optuna\n",
        "from plotly.io import show\n",
        "from datetime import datetime\n",
        "from optuna.trial import TrialState\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NNF7jP_TwbBu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K258Fig6RR22",
        "outputId": "437f46d1-0723-45a8-d81a-230d0aecf097"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting data pipeline: Attempting to download HYG star data...\n",
            "Trying URL: https://codeberg.org/astronexus/hyg/media/branch/main/data/hyg/CURRENT/hyg_v42.csv.gz\n",
            "Download successful.\n"
          ]
        }
      ],
      "source": [
        "# --- Dataset Download  ---\n",
        "def download_hyg_dataset():\n",
        "    \"\"\"\n",
        "    Attempts to download the gzipped CSV file from a list of URLs.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A pandas DataFrame of the HYG data if successful, None otherwise.\n",
        "    \"\"\"\n",
        "    # URLs to official public HYG data set repository and backup copy hosted on Google Drive.\n",
        "    HYG_URLS = ['https://codeberg.org/astronexus/hyg/media/branch/main/data/hyg/CURRENT/hyg_v42.csv.gz',\n",
        "                'https://drive.google.com/uc?export=download&id=1U2apsUPjQR_DllzF74y-pV3KjVTK3FJW']\n",
        "\n",
        "    hyg_file = None\n",
        "    print(\"\\nStarting data pipeline: Attempting to download HYG star data...\")\n",
        "\n",
        "    for url in HYG_URLS:\n",
        "        try:\n",
        "            print(f\"Trying URL: {url}\")\n",
        "            response = requests.get(url, timeout=30)\n",
        "            response.raise_for_status()\n",
        "            hyg_file = io.BytesIO(response.content)\n",
        "            hyg_df = pd.read_csv(hyg_file, compression='gzip')\n",
        "            print(\"Download successful.\")\n",
        "            return hyg_df\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error downloading from {url}: {e}\")\n",
        "            print(\"Trying next URL...\")\n",
        "        except Exception as e:\n",
        "            print(f\"An unexpected error occurred during data processing: {e}\")\n",
        "            return None\n",
        "\n",
        "    print(\"\\nAll download attempts failed. Please check your internet connection or the URLs.\")\n",
        "    return None\n",
        "\n",
        "# Download the data\n",
        "df = download_hyg_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByPuNT8QQtOB",
        "outputId": "4b94d0f9-4eef-4e1b-b6de-47fd4f239478"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- HYG Dataset Head (First 5 Rows) ---\n",
            "   id  hip        hd  hr   gl   bf proper        ra        dec      dist  \\\n",
            "0   0  NaN       NaN NaN  NaN  NaN    Sol  0.000000   0.000000    0.0000   \n",
            "1   1  1.0  224700.0 NaN  NaN  NaN    NaN  0.000060   1.089009  219.7802   \n",
            "2   2  2.0  224690.0 NaN  NaN  NaN    NaN  0.000283 -19.498840   47.9616   \n",
            "3   3  3.0  224699.0 NaN  NaN  NaN    NaN  0.000335  38.859279  442.4779   \n",
            "4   4  4.0  224707.0 NaN  NaN  NaN    NaN  0.000569 -51.893546  134.2282   \n",
            "\n",
            "     pmra  pmdec   rv    mag  absmag spect     ci           x         y  \\\n",
            "0    0.00   0.00  0.0 -26.70   4.850   G2V  0.656    0.000005  0.000000   \n",
            "1   -5.20  -1.88  0.0   9.10   2.390    F5  0.482  219.740502  0.003449   \n",
            "2  181.21  -0.93  0.0   9.27   5.866   K3V  0.999   45.210918  0.003365   \n",
            "3    5.24  -2.91  0.0   6.61  -1.619    B9 -0.019  344.552785  0.030213   \n",
            "4   62.85   0.16  0.0   8.06   2.421   F0V  0.370   82.835513  0.012476   \n",
            "\n",
            "            z            vx        vy            vz     rarad    decrad  \\\n",
            "0    0.000000  0.000000e+00  0.000000  0.000000e+00  0.000000  0.000000   \n",
            "1    4.177065  4.000000e-08 -0.000006 -2.000000e-06  0.000016  0.019007   \n",
            "2  -16.008996 -7.000000e-08  0.000042 -2.000000e-07  0.000074 -0.340319   \n",
            "3  277.614965  3.920000e-06  0.000011 -4.860000e-06  0.000088  0.678222   \n",
            "4 -105.619540  8.000000e-08  0.000041  6.000000e-08  0.000149 -0.905713   \n",
            "\n",
            "        pmrarad      pmdecrad bayer  flam  con  comp  comp_primary base  \\\n",
            "0  0.000000e+00  0.000000e+00   NaN   NaN  NaN     1             0  NaN   \n",
            "1 -2.521031e-08 -9.114497e-09   NaN   NaN  Psc     1             1  NaN   \n",
            "2  8.785309e-07 -4.508767e-09   NaN   NaN  Cet     1             2  NaN   \n",
            "3  2.540424e-08 -1.410808e-08   NaN   NaN  And     1             3  NaN   \n",
            "4  3.047054e-07  7.757010e-10   NaN   NaN  Phe     1             4  NaN   \n",
            "\n",
            "          lum  var  var_min  var_max  \n",
            "0    1.000000  NaN      NaN      NaN  \n",
            "1    9.638290  NaN      NaN      NaN  \n",
            "2    0.392283  NaN      NaN      NaN  \n",
            "3  386.901132  NaN      NaN      NaN  \n",
            "4    9.366989  NaN      NaN      NaN  \n",
            "\n",
            "--- Dataset Info ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 119626 entries, 0 to 119625\n",
            "Data columns (total 37 columns):\n",
            " #   Column        Non-Null Count   Dtype  \n",
            "---  ------        --------------   -----  \n",
            " 0   id            119626 non-null  int64  \n",
            " 1   hip           117951 non-null  float64\n",
            " 2   hd            98885 non-null   float64\n",
            " 3   hr            9041 non-null    float64\n",
            " 4   gl            3801 non-null    object \n",
            " 5   bf            3099 non-null    object \n",
            " 6   proper        499 non-null     object \n",
            " 7   ra            119626 non-null  float64\n",
            " 8   dec           119626 non-null  float64\n",
            " 9   dist          119626 non-null  float64\n",
            " 10  pmra          119626 non-null  float64\n",
            " 11  pmdec         119626 non-null  float64\n",
            " 12  rv            119626 non-null  float64\n",
            " 13  mag           119626 non-null  float64\n",
            " 14  absmag        119626 non-null  float64\n",
            " 15  spect         116578 non-null  object \n",
            " 16  ci            117735 non-null  float64\n",
            " 17  x             119626 non-null  float64\n",
            " 18  y             119626 non-null  float64\n",
            " 19  z             119626 non-null  float64\n",
            " 20  vx            119626 non-null  float64\n",
            " 21  vy            119626 non-null  float64\n",
            " 22  vz            119626 non-null  float64\n",
            " 23  rarad         119626 non-null  float64\n",
            " 24  decrad        119626 non-null  float64\n",
            " 25  pmrarad       119626 non-null  float64\n",
            " 26  pmdecrad      119626 non-null  float64\n",
            " 27  bayer         1537 non-null    object \n",
            " 28  flam          2737 non-null    float64\n",
            " 29  con           119625 non-null  object \n",
            " 30  comp          119626 non-null  int64  \n",
            " 31  comp_primary  119626 non-null  int64  \n",
            " 32  base          1086 non-null    object \n",
            " 33  lum           119626 non-null  float64\n",
            " 34  var           5992 non-null    object \n",
            " 35  var_min       16991 non-null   float64\n",
            " 36  var_max       16991 non-null   float64\n",
            "dtypes: float64(26), int64(3), object(8)\n",
            "memory usage: 33.8+ MB\n",
            "\n",
            "There are 4309 unique spectral types in the dataset.\n",
            "\n",
            "--- Rarest Spectral Types Sample ---\n",
            "spect\n",
            "G0Iab         1\n",
            "G5IIIp        1\n",
            "A4/A7:m...    1\n",
            "F5Ib/II       1\n",
            "B2IIn...      1\n",
            "DAe           1\n",
            "F5V: + F      1\n",
            "O9.5Iab-Ib    1\n",
            "B4:V:ne       1\n",
            "M0III SB      1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Number of spectral types that appear only once: 2401\n",
            "Number of spectral types that appear only twice: 567\n"
          ]
        }
      ],
      "source": [
        "# --- Dataset Inspection ---\n",
        "# Set pandas display options to see all columns\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "print(\"\\n--- HYG Dataset Head (First 5 Rows) ---\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\n--- Dataset Info ---\")\n",
        "df.info()\n",
        "\n",
        "unique_spect_count = df['spect'].nunique(dropna=True)\n",
        "print(f\"\\nThere are {unique_spect_count} unique spectral types in the dataset.\")\n",
        "\n",
        "# Count the occurrences of each spectral type\n",
        "spect_counts = df['spect'].value_counts()\n",
        "\n",
        "# This will show spectral types with the lowest counts\n",
        "rarest_spect_types = spect_counts.tail(10)\n",
        "print(\"\\n--- Rarest Spectral Types Sample ---\")\n",
        "print(rarest_spect_types)\n",
        "\n",
        "# Get a summary of how many types appear only a few times\n",
        "types_with_one_occurrence = (spect_counts == 1).sum()\n",
        "types_with_two_occurrences = (spect_counts == 2).sum()\n",
        "\n",
        "print(f\"\\nNumber of spectral types that appear only once: {types_with_one_occurrence}\")\n",
        "print(f\"Number of spectral types that appear only twice: {types_with_two_occurrences}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfLqaPbu9hFk",
        "outputId": "3570eaaa-9f91-49d4-d754-7c623802663a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset size: 119626\n",
            "Filtered dataset size after dropping rows with missing features: 115368\n",
            "\n",
            "Training set size: 92294 samples\n",
            "Validation set size: 23074 samples\n"
          ]
        }
      ],
      "source": [
        "# --- 2. Data Preprocessing and Feature Selection ---\n",
        "\n",
        "print(f\"Original dataset size: {len(df)}\")\n",
        "\n",
        "# For simplicity, only use stars with non-null values for the chosen features.\n",
        "features = ['absmag', 'ci', 'spect']\n",
        "df_filtered = df.dropna(subset=features)\n",
        "print(f\"Filtered dataset size after dropping rows with missing features: {len(df_filtered)}\")\n",
        "\n",
        "# Prepare numerical and categorical data\n",
        "numerical_features = df_filtered[['absmag', 'ci']]\n",
        "\n",
        "# Scale the numerical features\n",
        "scaler = StandardScaler()\n",
        "scaled_numerical_features = scaler.fit_transform(numerical_features)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "# We split the numerical features, the encoded spectral types, and the star info\n",
        "X_num_train, X_num_val = train_test_split(scaled_numerical_features, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert the NumPy arrays to PyTorch tensors\n",
        "X_num_train = torch.tensor(X_num_train, dtype=torch.float32)\n",
        "X_num_val = torch.tensor(X_num_val, dtype=torch.float32)\n",
        "\n",
        "# Create TensorDatasets for training and validation\n",
        "# Note that we are passing both the numerical and categorical tensors\n",
        "train_dataset = TensorDataset(X_num_train)\n",
        "val_dataset = TensorDataset(X_num_val)\n",
        "\n",
        "# Create DataLoaders for training and validation\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "print(f\"\\nTraining set size: {len(X_num_train)} samples\")\n",
        "print(f\"Validation set size: {len(X_num_val)} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5A-IIDU8zgpQ"
      },
      "outputs": [],
      "source": [
        "def print_model_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the name and shape of each parameter in a PyTorch model.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Model Parameters ---\")\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            print(f\"Layer: {name:<25} | Shape: {list(param.shape)}\")\n",
        "    print(\"------------------------\\n\")\n",
        "\n",
        "def save_checkpoint(trial, model, best_val_loss, file_path):\n",
        "    \"\"\"\n",
        "    Saves a dictionary containing the model's state, hyperparameters, and trial info.\n",
        "\n",
        "    Args:\n",
        "        trial (optuna.trial.Trial): The current Optuna trial object.\n",
        "        model (torch.nn.Module): The model to save.\n",
        "        best_val_loss (float): The best validation loss achieved so far.\n",
        "        file_path (str): The full path for the checkpoint file.\n",
        "    \"\"\"\n",
        "    # Create the checkpoint dictionary\n",
        "    checkpoint = {\n",
        "        'trial_number': trial.number,\n",
        "        'hyperparameters': trial.params,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'val_loss': best_val_loss\n",
        "    }\n",
        "\n",
        "    # Save the checkpoint to a uniquely named file\n",
        "    torch.save(checkpoint, file_path)\n",
        "    print(f\"Checkpoint saved for Trial {trial.number} with a new best Val Loss of {best_val_loss:.4f} to {file_path}\")\n",
        "\n",
        "def save_study_metadata(study: optuna.study.Study, file_path: str):\n",
        "    \"\"\"\n",
        "    Saves the metadata of an Optuna study to a JSON file.\n",
        "\n",
        "    Args:\n",
        "        study (optuna.study.Study): The Optuna study object to save.\n",
        "        file_path (str): The full path to the output JSON file in Google Drive.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Get the current time for the log\n",
        "        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "        # Extract essential information from the best trial\n",
        "        best_trial = study.best_trial\n",
        "        best_params = best_trial.params\n",
        "        best_value = best_trial.value\n",
        "\n",
        "        # Create a dictionary to hold the metadata\n",
        "        metadata = {\n",
        "            \"study_name\": study.study_name,\n",
        "            \"timestamp\": timestamp,\n",
        "            \"best_value\": best_value,\n",
        "            \"best_params\": best_params,\n",
        "            \"state\": str(study.best_trial.state),\n",
        "            \"user_attributes\": study.best_trial.user_attrs,\n",
        "            \"study_direction\": str(study.direction),\n",
        "            \"trials_completed\": len(study.trials)\n",
        "        }\n",
        "\n",
        "        # Convert the dictionary to a JSON string\n",
        "        json_metadata = json.dumps(metadata, indent=4, sort_keys=True)\n",
        "\n",
        "        # Write the JSON string to the specified file\n",
        "        with open(file_path, 'w') as f:\n",
        "            f.write(json_metadata)\n",
        "\n",
        "        print(f\"Study metadata successfully saved to: {file_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while saving study metadata: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mG9rQol69XDG"
      },
      "outputs": [],
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_numerical_features: int,\n",
        "                 n_encoder_layers: int,\n",
        "                 n_hidden_neurons: int,\n",
        "                 dropout_rate: float,\n",
        "                 latent_dim: int=2):\n",
        "\n",
        "        super(Autoencoder, self).__init__()\n",
        "\n",
        "        # Save this for the forward pass\n",
        "        self.num_numerical_features = num_numerical_features\n",
        "\n",
        "        # Dynamically build the encoder\n",
        "        encoder_layers = []\n",
        "        # Store layer dimensions to mirror in the decoder\n",
        "        layer_dims = [num_numerical_features] # Start with the number of numerical features as input\n",
        "        for i in range(n_encoder_layers):\n",
        "            # The input dimension for the first encoder layer is num_numerical_features\n",
        "            input_dim = layer_dims[-1]\n",
        "            # The output dimension is calculated based on n_hidden_neurons and latent_dim\n",
        "            output_dim = n_hidden_neurons // (2**i) if i < n_encoder_layers - 1 else latent_dim\n",
        "            encoder_layers.append(nn.Linear(input_dim, output_dim))\n",
        "            encoder_layers.append(nn.ReLU())\n",
        "            encoder_layers.append(nn.Dropout(dropout_rate))\n",
        "            layer_dims.append(output_dim)\n",
        "        self.encoder = nn.Sequential(*encoder_layers)\n",
        "\n",
        "        # Dynamically build the decoder by reversing the layer dimensions\n",
        "        decoder_layers = []\n",
        "        # The decoder starts from the latent dimension\n",
        "        reversed_dims = list(reversed(layer_dims))\n",
        "        for i in range(len(reversed_dims) - 1):\n",
        "            decoder_layers.append(nn.Linear(reversed_dims[i], reversed_dims[i+1]))\n",
        "            # Add ReLU for all but the final layer\n",
        "            if i < len(reversed_dims) - 2:\n",
        "                decoder_layers.append(nn.ReLU())\n",
        "\n",
        "        self.decoder = nn.Sequential(*decoder_layers)\n",
        "\n",
        "\n",
        "    def forward(self, x_num):\n",
        "        # Pass the tensor through the encoder to get the latent representation\n",
        "        latent_coords = self.encoder(x_num)\n",
        "\n",
        "        # Pass the latent representation through the decoder to get a reconstruction\n",
        "        reconstruction = self.decoder(latent_coords)\n",
        "\n",
        "        # The decoder now reconstructs the original numerical features directly\n",
        "        return latent_coords, reconstruction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OD6tlfuS9p4x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a93052a1-1d48-4cef-f706-ad8912041970"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU not available, using CPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-09-22 00:14:34,160] Using an existing study with name 'AE_HRParams_Latent_Wide_r2' instead of creating a new one.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Model Parameters ---\n",
            "Layer: encoder.0.weight          | Shape: [144, 2]\n",
            "Layer: encoder.0.bias            | Shape: [144]\n",
            "Layer: encoder.3.weight          | Shape: [72, 144]\n",
            "Layer: encoder.3.bias            | Shape: [72]\n",
            "Layer: encoder.6.weight          | Shape: [36, 72]\n",
            "Layer: encoder.6.bias            | Shape: [36]\n",
            "Layer: encoder.9.weight          | Shape: [2, 36]\n",
            "Layer: encoder.9.bias            | Shape: [2]\n",
            "Layer: decoder.0.weight          | Shape: [36, 2]\n",
            "Layer: decoder.0.bias            | Shape: [36]\n",
            "Layer: decoder.2.weight          | Shape: [72, 36]\n",
            "Layer: decoder.2.bias            | Shape: [72]\n",
            "Layer: decoder.4.weight          | Shape: [144, 72]\n",
            "Layer: decoder.4.bias            | Shape: [144]\n",
            "Layer: decoder.6.weight          | Shape: [2, 144]\n",
            "Layer: decoder.6.bias            | Shape: [2]\n",
            "------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-09-22 00:14:46,952] Trial 50 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved for Trial 50 with a new best Val Loss of 0.3739 to /content/drive/MyDrive/Checkpoints/AE_HRParams_Latent_Wide_r2_trial_50_best.pth\n",
            "Trial 50: Pruning trial at epoch 1.\n",
            "\n",
            "--- Model Parameters ---\n",
            "Layer: encoder.0.weight          | Shape: [128, 2]\n",
            "Layer: encoder.0.bias            | Shape: [128]\n",
            "Layer: encoder.3.weight          | Shape: [64, 128]\n",
            "Layer: encoder.3.bias            | Shape: [64]\n",
            "Layer: encoder.6.weight          | Shape: [32, 64]\n",
            "Layer: encoder.6.bias            | Shape: [32]\n",
            "Layer: encoder.9.weight          | Shape: [2, 32]\n",
            "Layer: encoder.9.bias            | Shape: [2]\n",
            "Layer: decoder.0.weight          | Shape: [32, 2]\n",
            "Layer: decoder.0.bias            | Shape: [32]\n",
            "Layer: decoder.2.weight          | Shape: [64, 32]\n",
            "Layer: decoder.2.bias            | Shape: [64]\n",
            "Layer: decoder.4.weight          | Shape: [128, 64]\n",
            "Layer: decoder.4.bias            | Shape: [128]\n",
            "Layer: decoder.6.weight          | Shape: [2, 128]\n",
            "Layer: decoder.6.bias            | Shape: [2]\n",
            "------------------------\n",
            "\n",
            "Checkpoint saved for Trial 51 with a new best Val Loss of 0.1262 to /content/drive/MyDrive/Checkpoints/AE_HRParams_Latent_Wide_r2_trial_51_best.pth\n",
            "Trial 51, Epoch [1/100], Val Loss: 0.1262\n",
            "Checkpoint saved for Trial 51 with a new best Val Loss of 0.0385 to /content/drive/MyDrive/Checkpoints/AE_HRParams_Latent_Wide_r2_trial_51_best.pth\n",
            "Trial 51, Epoch [2/100], Val Loss: 0.0385\n",
            "Trial 51, Epoch [3/100], Val Loss: 0.0424\n",
            "Trial 51, Epoch [4/100], Val Loss: 0.0566\n",
            "Trial 51, Epoch [5/100], Val Loss: 0.2566\n",
            "Checkpoint saved for Trial 51 with a new best Val Loss of 0.0219 to /content/drive/MyDrive/Checkpoints/AE_HRParams_Latent_Wide_r2_trial_51_best.pth\n",
            "Trial 51, Epoch [6/100], Val Loss: 0.0219\n",
            "Trial 51, Epoch [7/100], Val Loss: 0.0328\n",
            "Trial 51, Epoch [8/100], Val Loss: 0.0390\n",
            "Trial 51, Epoch [9/100], Val Loss: 0.0225\n",
            "Trial 51, Epoch [10/100], Val Loss: 0.0248\n",
            "Trial 51, Epoch [11/100], Val Loss: 0.0306\n",
            "Trial 51, Epoch [12/100], Val Loss: 0.5196\n",
            "Checkpoint saved for Trial 51 with a new best Val Loss of 0.0168 to /content/drive/MyDrive/Checkpoints/AE_HRParams_Latent_Wide_r2_trial_51_best.pth\n",
            "Trial 51, Epoch [13/100], Val Loss: 0.0168\n",
            "Trial 51, Epoch [14/100], Val Loss: 0.0304\n",
            "Trial 51, Epoch [15/100], Val Loss: 0.0301\n",
            "Trial 51, Epoch [16/100], Val Loss: 0.0867\n",
            "Trial 51, Epoch [17/100], Val Loss: 0.0794\n",
            "Trial 51, Epoch [18/100], Val Loss: 0.0199\n",
            "Trial 51, Epoch [19/100], Val Loss: 0.0593\n",
            "Trial 51, Epoch [20/100], Val Loss: 0.0310\n",
            "Trial 51, Epoch [21/100], Val Loss: 0.0583\n",
            "Trial 51, Epoch [22/100], Val Loss: 0.0185\n",
            "Trial 51, Epoch [23/100], Val Loss: 0.1046\n",
            "Trial 51, Epoch [24/100], Val Loss: 0.0182\n",
            "Trial 51, Epoch [25/100], Val Loss: 0.0242\n",
            "Trial 51, Epoch [26/100], Val Loss: 0.0609\n",
            "Trial 51, Epoch [27/100], Val Loss: 0.0922\n",
            "Trial 51, Epoch [28/100], Val Loss: 0.0182\n",
            "Trial 51, Epoch [29/100], Val Loss: 0.0454\n",
            "Trial 51, Epoch [30/100], Val Loss: 0.0379\n",
            "Trial 51, Epoch [31/100], Val Loss: 0.0177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-09-22 00:17:45,068] Trial 51 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 51: Pruning trial at epoch 32.\n",
            "\n",
            "--- Model Parameters ---\n",
            "Layer: encoder.0.weight          | Shape: [144, 2]\n",
            "Layer: encoder.0.bias            | Shape: [144]\n",
            "Layer: encoder.3.weight          | Shape: [72, 144]\n",
            "Layer: encoder.3.bias            | Shape: [72]\n",
            "Layer: encoder.6.weight          | Shape: [36, 72]\n",
            "Layer: encoder.6.bias            | Shape: [36]\n",
            "Layer: encoder.9.weight          | Shape: [2, 36]\n",
            "Layer: encoder.9.bias            | Shape: [2]\n",
            "Layer: decoder.0.weight          | Shape: [36, 2]\n",
            "Layer: decoder.0.bias            | Shape: [36]\n",
            "Layer: decoder.2.weight          | Shape: [72, 36]\n",
            "Layer: decoder.2.bias            | Shape: [72]\n",
            "Layer: decoder.4.weight          | Shape: [144, 72]\n",
            "Layer: decoder.4.bias            | Shape: [144]\n",
            "Layer: decoder.6.weight          | Shape: [2, 144]\n",
            "Layer: decoder.6.bias            | Shape: [2]\n",
            "------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-09-22 00:17:50,574] Trial 52 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved for Trial 52 with a new best Val Loss of 3.6427 to /content/drive/MyDrive/Checkpoints/AE_HRParams_Latent_Wide_r2_trial_52_best.pth\n",
            "Trial 52: Pruning trial at epoch 1.\n",
            "\n",
            "--- Model Parameters ---\n",
            "Layer: encoder.0.weight          | Shape: [128, 2]\n",
            "Layer: encoder.0.bias            | Shape: [128]\n",
            "Layer: encoder.3.weight          | Shape: [64, 128]\n",
            "Layer: encoder.3.bias            | Shape: [64]\n",
            "Layer: encoder.6.weight          | Shape: [32, 64]\n",
            "Layer: encoder.6.bias            | Shape: [32]\n",
            "Layer: encoder.9.weight          | Shape: [2, 32]\n",
            "Layer: encoder.9.bias            | Shape: [2]\n",
            "Layer: decoder.0.weight          | Shape: [32, 2]\n",
            "Layer: decoder.0.bias            | Shape: [32]\n",
            "Layer: decoder.2.weight          | Shape: [64, 32]\n",
            "Layer: decoder.2.bias            | Shape: [64]\n",
            "Layer: decoder.4.weight          | Shape: [128, 64]\n",
            "Layer: decoder.4.bias            | Shape: [128]\n",
            "Layer: decoder.6.weight          | Shape: [2, 128]\n",
            "Layer: decoder.6.bias            | Shape: [2]\n",
            "------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-09-22 00:17:55,385] Trial 53 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved for Trial 53 with a new best Val Loss of 0.2138 to /content/drive/MyDrive/Checkpoints/AE_HRParams_Latent_Wide_r2_trial_53_best.pth\n",
            "Trial 53: Pruning trial at epoch 1.\n",
            "\n",
            "--- Model Parameters ---\n",
            "Layer: encoder.0.weight          | Shape: [112, 2]\n",
            "Layer: encoder.0.bias            | Shape: [112]\n",
            "Layer: encoder.3.weight          | Shape: [56, 112]\n",
            "Layer: encoder.3.bias            | Shape: [56]\n",
            "Layer: encoder.6.weight          | Shape: [28, 56]\n",
            "Layer: encoder.6.bias            | Shape: [28]\n",
            "Layer: encoder.9.weight          | Shape: [2, 28]\n",
            "Layer: encoder.9.bias            | Shape: [2]\n",
            "Layer: decoder.0.weight          | Shape: [28, 2]\n",
            "Layer: decoder.0.bias            | Shape: [28]\n",
            "Layer: decoder.2.weight          | Shape: [56, 28]\n",
            "Layer: decoder.2.bias            | Shape: [56]\n",
            "Layer: decoder.4.weight          | Shape: [112, 56]\n",
            "Layer: decoder.4.bias            | Shape: [112]\n",
            "Layer: decoder.6.weight          | Shape: [2, 112]\n",
            "Layer: decoder.6.bias            | Shape: [2]\n",
            "------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-09-22 00:18:01,349] Trial 54 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved for Trial 54 with a new best Val Loss of 0.4693 to /content/drive/MyDrive/Checkpoints/AE_HRParams_Latent_Wide_r2_trial_54_best.pth\n",
            "Trial 54: Pruning trial at epoch 1.\n",
            "Study metadata successfully saved to: /content/drive/MyDrive/Logs/AE_HRParams_Latent_Wide_r2.json\n"
          ]
        }
      ],
      "source": [
        "# --- 5. Main Execution and Export ---\n",
        "def objective(trial, device, study_name):\n",
        "\n",
        "    # Hyperparameters to be tuned by Optuna\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)\n",
        "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.0, 0.05)\n",
        "    n_encoder_layers = trial.suggest_int(\"n_encoder_layers\", 3, 4)\n",
        "    n_hidden_neurons = trial.suggest_int(\"n_hidden_neurons\", 64, 192, step=16)\n",
        "\n",
        "    # Define the model with the suggested hyperparameters\n",
        "    model = Autoencoder(\n",
        "            num_numerical_features=len(features) - 1,  # 'absmag', 'ci' - 'spect'\n",
        "            n_encoder_layers=n_encoder_layers,\n",
        "            n_hidden_neurons=n_hidden_neurons,\n",
        "            dropout_rate=dropout_rate\n",
        "            ).to(device)\n",
        "\n",
        "    # Define the optimizer and scheduler\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='min',\n",
        "    factor=0.5,\n",
        "    patience=20)\n",
        "\n",
        "    print_model_parameters(model)\n",
        "\n",
        "    # Training Loop with Early Stopping\n",
        "    patience = 25\n",
        "    epochs_no_improve = 0\n",
        "    best_val_loss = float('inf')\n",
        "    epochs = 100 # Set a reasonable max number of epochs per trial\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        for batch in train_dataloader:\n",
        "            batch = batch[0].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Corrected forward pass with new returns\n",
        "            latent_coords, reconstructed_num = model(batch)\n",
        "\n",
        "            numerical_loss = F.mse_loss(batch, reconstructed_num)\n",
        "            loss = numerical_loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        total_val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in val_dataloader:\n",
        "                batch = batch[0].to(device)\n",
        "\n",
        "                # Corrected forward pass with new returns\n",
        "                latent_coords, reconstructed_num = model(batch)\n",
        "\n",
        "                val_loss = F.mse_loss(batch, reconstructed_num)\n",
        "\n",
        "                total_val_loss += val_loss.item() * batch.size(0)\n",
        "\n",
        "        avg_val_loss = total_val_loss / len(val_dataloader)\n",
        "\n",
        "        # Early Stopping and Pruning\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            epochs_no_improve = 0\n",
        "            checkpoint_path = f'/content/drive/MyDrive/Checkpoints/{study_name}_trial_{trial.number}_best.pth'\n",
        "            os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
        "            save_checkpoint(trial, model, best_val_loss, checkpoint_path)\n",
        "\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                print(f\"Trial {trial.number}: Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "        # Report the loss to Optuna\n",
        "        trial.report(avg_val_loss, epoch)\n",
        "\n",
        "        # Prune the trial if it's not performing well\n",
        "        if trial.should_prune():\n",
        "            print(f\"Trial {trial.number}: Pruning trial at epoch {epoch + 1}.\")\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "        print(f\"Trial {trial.number}, Epoch [{epoch + 1}/{epochs}], Val Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "    return best_val_loss\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    study_name = 'AE_HRParams_Latent_Wide_r2'\n",
        "    # Set up the device (CPU or GPU)\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "        print(\"GPU is available and will be used.\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "        print(\"GPU not available, using CPU.\")\n",
        "    # Hyperparameter Tuning with Optuna\n",
        "    # This will find the best hyperparameters by running multiple trials.\n",
        "    # The 'objective' function is defined separately and contains the training loop.\n",
        "    study = optuna.create_study(\n",
        "            direction=\"minimize\",\n",
        "            storage=f\"sqlite:////content/drive/MyDrive/Data/{study_name}.db\",\n",
        "            study_name=f\"{study_name}\",\n",
        "            load_if_exists=True)\n",
        "    study.optimize(lambda trial: objective(trial, device, study_name), n_trials=5)\n",
        "\n",
        "    # Call the function to save the metadata\n",
        "    output_path = f'/content/drive/MyDrive/Logs/{study_name}.json'\n",
        "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "    save_study_metadata(study, output_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VIAB8LsyVa2R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "118ba489-7e80-4e40-d014-0ae9cb29963a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-3.1.0.min.js\" integrity=\"sha256-Ei4740bWZhaUTQuD6q9yQlgVCMPBz6CZWhevDYPv93A=\" crossorigin=\"anonymous\"></script>                <div id=\"7d4f050f-cf32-4d24-a126-e35de4d1497d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById(\"7d4f050f-cf32-4d24-a126-e35de4d1497d\")) {                    Plotly.newPlot(                        \"7d4f050f-cf32-4d24-a126-e35de4d1497d\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,10,11,12,13,16,22,28,31,41,47],\"y\":[0.04393286147097466,2.0948764205267887,0.04363148685395098,1.6424577335035042,0.9038163482461775,0.0042797584704246305,0.005617364387103218,0.005076777789944272,0.003541752888981177,0.001895396718053164,0.0027775592409694113,0.004597590756725934,0.002249933193212664,0.0028397329255932563,0.0010102221465261958],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54],\"y\":[0.04393286147097466,0.04393286147097466,0.04363148685395098,0.04363148685395098,0.04363148685395098,0.04363148685395098,0.04363148685395098,0.04363148685395098,0.04363148685395098,0.04363148685395098,0.0042797584704246305,0.0042797584704246305,0.0042797584704246305,0.003541752888981177,0.003541752888981177,0.003541752888981177,0.001895396718053164,0.001895396718053164,0.001895396718053164,0.001895396718053164,0.001895396718053164,0.001895396718053164,0.001895396718053164,0.001895396718053164,0.001895396718053164,0.001895396718053164,0.001895396718053164,0.001895396718053164,0.001895396718053164,0.001895396718053164,0.001895396718053164,0.001895396718053164,0.001895396718053164,0.001895396718053164,0.001895396718053164,0.001895396718053164,0.001895396718053164,0.001895396718053164,0.001895396718053164,0.001895396718053164,0.001895396718053164,0.001895396718053164,0.001895396718053164,0.001895396718053164,0.001895396718053164,0.001895396718053164,0.001895396718053164,0.0010102221465261958,0.0010102221465261958,0.0010102221465261958,0.0010102221465261958,0.0010102221465261958,0.0010102221465261958,0.0010102221465261958,0.0010102221465261958],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#cccccc\"},\"mode\":\"markers\",\"name\":\"Infeasible Trial\",\"showlegend\":false,\"x\":[],\"y\":[],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermap\":[{\"type\":\"scattermap\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('7d4f050f-cf32-4d24-a126-e35de4d1497d');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-3.1.0.min.js\" integrity=\"sha256-Ei4740bWZhaUTQuD6q9yQlgVCMPBz6CZWhevDYPv93A=\" crossorigin=\"anonymous\"></script>                <div id=\"cbfedc24-3a1f-452a-b492-95984e2d1e07\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById(\"cbfedc24-3a1f-452a-b492-95984e2d1e07\")) {                    Plotly.newPlot(                        \"cbfedc24-3a1f-452a-b492-95984e2d1e07\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"n_hidden_neurons (IntDistribution): 0.058416696632162535\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"n_encoder_layers (IntDistribution): 0.09431909029736327\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"learning_rate (FloatDistribution): 0.1348356231676222\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"dropout_rate (FloatDistribution): 0.7124285899028521\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"],\"name\":\"Objective Value\",\"orientation\":\"h\",\"text\":[\"0.06\",\"0.09\",\"0.13\",\"0.71\"],\"textposition\":\"outside\",\"x\":[0.058416696632162535,0.09431909029736327,0.1348356231676222,0.7124285899028521],\"y\":[\"n_hidden_neurons\",\"n_encoder_layers\",\"learning_rate\",\"dropout_rate\"],\"type\":\"bar\"}],                        {\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Hyperparameter Importance\"}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermap\":[{\"type\":\"scattermap\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('cbfedc24-3a1f-452a-b492-95984e2d1e07');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-3.1.0.min.js\" integrity=\"sha256-Ei4740bWZhaUTQuD6q9yQlgVCMPBz6CZWhevDYPv93A=\" crossorigin=\"anonymous\"></script>                <div id=\"3d1f01cc-cf93-418c-a547-efa0bfcc188f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById(\"3d1f01cc-cf93-418c-a547-efa0bfcc188f\")) {                    Plotly.newPlot(                        \"3d1f01cc-cf93-418c-a547-efa0bfcc188f\",                        [{\"dimensions\":[{\"label\":\"Objective Value\",\"range\":[0.0010102221465261958,2.0948764205267887],\"values\":[0.04393286147097466,2.0948764205267887,0.04363148685395098,1.6424577335035042,0.9038163482461775,0.0042797584704246305,0.005617364387103218,0.005076777789944272,0.003541752888981177,0.001895396718053164,0.0027775592409694113,0.004597590756725934,0.002249933193212664,0.0028397329255932563,0.0010102221465261958]},{\"label\":\"dropout_rate\",\"range\":[0.00004017879071960994,0.04282074756613327],\"values\":[0.008765324253623996,0.017622856304514045,0.00857639187801641,0.04282074756613327,0.01572930124801559,0.0001279708595824207,0.0009087784349417427,0.0015820507565678045,0.00029795826656970616,0.0007123105495599142,0.0008977127142757342,0.0002462462486788822,0.0003963467325245729,0.00004017879071960994,0.0002484875027900211]},{\"label\":\"learning_rate\",\"range\":[-3.5381664930366905,-2.0127394388227184],\"ticktext\":[\"0.00029\",\"0.001\",\"0.00971\"],\"tickvals\":[-3.5381664930366905,-3,-2.0127394388227184],\"values\":[-2.544205079353854,-2.324878039962548,-2.857956797705901,-3.3603500391572263,-2.0127394388227184,-2.951592653069676,-2.939061826106599,-3.029792162571187,-3.18037861150403,-3.2147804991242643,-3.5381664930366905,-3.474357828320161,-2.9260754998356404,-2.9347736293120503,-2.900308858285287]},{\"label\":\"n_encoder_layers\",\"range\":[1,3],\"values\":[3,3,3,1,1,3,3,3,3,2,3,3,3,3,2]},{\"label\":\"n_hidden_neurons\",\"range\":[80,192],\"values\":[80,112,176,176,192,144,144,144,128,128,144,96,144,144,112]}],\"labelangle\":30,\"labelside\":\"bottom\",\"line\":{\"color\":[0.04393286147097466,2.0948764205267887,0.04363148685395098,1.6424577335035042,0.9038163482461775,0.0042797584704246305,0.005617364387103218,0.005076777789944272,0.003541752888981177,0.001895396718053164,0.0027775592409694113,0.004597590756725934,0.002249933193212664,0.0028397329255932563,0.0010102221465261958],\"colorbar\":{\"title\":{\"text\":\"Objective Value\"}},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"reversescale\":true,\"showscale\":true},\"type\":\"parcoords\"}],                        {\"title\":{\"text\":\"Parallel Coordinate Plot\"},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermap\":[{\"type\":\"scattermap\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('3d1f01cc-cf93-418c-a547-efa0bfcc188f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig_1 = optuna.visualization.plot_optimization_history(study)\n",
        "fig_1.write_image(f'/content/drive/MyDrive/Plots/{study_name}_history.png')\n",
        "show(fig_1)\n",
        "fig_2 = optuna.visualization.plot_param_importances(study)\n",
        "fig_2.write_image(f'/content/drive/MyDrive/Plots/{study_name}_importances.png')\n",
        "show(fig_2)\n",
        "fig_3 = optuna.visualization.plot_parallel_coordinate(study)\n",
        "fig_3.write_image(f'/content/drive/MyDrive/Plots/{study_name}_parallel.png')\n",
        "show(fig_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "FSyCxpa7gOn3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "537c8f28-c018-4139-f6ce-222bb4c8868a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best study trial: 47\n",
            "Best validation loss: 0.0010102221465261958\n",
            "Best hyperparameters found by Optuna: {'learning_rate': 0.0012580304169680257, 'dropout_rate': 0.0002484875027900211, 'n_encoder_layers': 2, 'n_hidden_neurons': 112}\n",
            "Best model loaded from '/content/drive/MyDrive/Checkpoints/AE_HRParams_Latent_Wide_r2_trial_47_best.pth'\n",
            "Generating 2D coordinates for all stars.\n"
          ]
        }
      ],
      "source": [
        "# Get the best trial's parameters and value\n",
        "best_params = study.best_trial.params\n",
        "best_loss = study.best_trial.value\n",
        "best_trial = study.best_trial.number\n",
        "best_weights_url = f'/content/drive/MyDrive/Checkpoints/{study_name}_trial_{best_trial}_best.pth'\n",
        "best_weights = torch.load(best_weights_url)['model_state_dict']\n",
        "print(f'\\nBest study trial:', best_trial)\n",
        "print(f\"Best validation loss: {best_loss}\")\n",
        "print(f'Best hyperparameters found by Optuna:', best_params)\n",
        "\n",
        "# 2. Re-instantiate and Train the Best Model\n",
        "# We create a new model with the best parameters found by Optuna\n",
        "best_model = Autoencoder(\n",
        "             num_numerical_features=len(features)-1,\n",
        "             n_encoder_layers=best_params['n_encoder_layers'],\n",
        "             n_hidden_neurons=best_params['n_hidden_neurons'],\n",
        "             dropout_rate=best_params['dropout_rate'])\n",
        "\n",
        "# Load the best model weights that were saved during the tuning process\n",
        "best_model.load_state_dict(best_weights)\n",
        "\n",
        "# The best model is already trained. No need to re-train.\n",
        "print(f\"Best model loaded from '{best_weights_url}'\")\n",
        "\n",
        "# 3. Generate Coordinates for ALL Stars\n",
        "# This is a crucial step to get the full star map, not just the validation set.\n",
        "print(\"Generating 2D coordinates for all stars.\")\n",
        "best_model.eval() # Set model to evaluation mode\n",
        "\n",
        "# Re-create the full tensor datasets for a clean, deterministic output.\n",
        "scaled_numerical_features = scaler.fit_transform(df_filtered[['absmag', 'ci']])\n",
        "\n",
        "full_dataset = TensorDataset(torch.tensor(scaled_numerical_features, dtype=torch.float32))\n",
        "full_dataloader = DataLoader(full_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "all_coords = []\n",
        "with torch.no_grad():\n",
        "    for batch in full_dataloader:\n",
        "        coords, _ = best_model(batch[0])\n",
        "        all_coords.extend(coords.numpy().tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "tMKSYVo0CU-0"
      },
      "outputs": [],
      "source": [
        "def process_spectral_type(spect_string):\n",
        "    \"\"\"\n",
        "    Cleans and simplifies the spectral type string for visualization.\n",
        "\n",
        "    Args:\n",
        "        spect_string (str): The raw spectral type string.\n",
        "\n",
        "    Returns:\n",
        "        str: The processed spectral type string (e.g., 'G2').\n",
        "    \"\"\"\n",
        "    if pd.isna(spect_string):\n",
        "        return 'UNKNOWN'\n",
        "\n",
        "    spect_string = spect_string.upper().strip()\n",
        "\n",
        "    # Handle stars with multiple values (e.g., 'F3/F5V') by taking the first one\n",
        "    if '/' in spect_string:\n",
        "        spect_string = spect_string.split('/')[0]\n",
        "\n",
        "    # Take the first two characters.\n",
        "    simplified = spect_string[:2]\n",
        "\n",
        "    # Check if the second character is not a digit.\n",
        "    if len(simplified) < 2 or not simplified[1].isdigit():\n",
        "        # Assign a default of '5' for stars with no number (e.g., 'M', 'K', 'O')\n",
        "        simplified = simplified[0] + '5'\n",
        "\n",
        "    return simplified"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "SV-y-rQPZp0A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "072fb2eb-3dd7-4d57-b9c6-e12d90e66496"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Essential star data saved to '/content/drive/MyDrive/Data/AE_HRParams_Latent_Wide_r2_front.csv.gz'\n"
          ]
        }
      ],
      "source": [
        "def export_star_data_to_csv_gz(df_filtered, all_coords, output_path):\n",
        "    \"\"\"\n",
        "    Combines filtered star data with latent space coordinates and exports it\n",
        "    to a compressed CSV file.\n",
        "\n",
        "    This function removes unnecessary fields and includes only the data\n",
        "    required for the front-end visualization, resulting in a significantly\n",
        "    smaller and more efficient file.\n",
        "\n",
        "    Args:\n",
        "        df_filtered (pd.DataFrame): DataFrame containing filtered star data\n",
        "                                     (e.g., from the HYG database).\n",
        "        all_coords (list of lists): The latent space coordinates for each star.\n",
        "        output_path (str): The full path to save the gzipped CSV file.\n",
        "    \"\"\"\n",
        "    # 1. Create a DataFrame for the latent space coordinates\n",
        "    latent_df = pd.DataFrame(all_coords, columns=['latent_x', 'latent_y',])\n",
        "\n",
        "    # Reset index of the filtered DataFrame for a clean merge\n",
        "    df_filtered = df_filtered.reset_index(drop=True)\n",
        "\n",
        "    # 2. Combine the original star data with the new latent space data\n",
        "    combined_df = pd.concat([df_filtered, latent_df], axis=1)\n",
        "\n",
        "    # 3. Process the 'spect' column using the new function\n",
        "    combined_df['spect'] = combined_df['spect'].apply(process_spectral_type)\n",
        "\n",
        "    # 4. Select and reorder only the essential columns\n",
        "    essential_df = combined_df[[\n",
        "        'id',\n",
        "        'latent_x',\n",
        "        'latent_y',\n",
        "        'x',\n",
        "        'y',\n",
        "        'z',\n",
        "        'absmag',\n",
        "        'spect'\n",
        "    ]]\n",
        "\n",
        "    # 5. Round the floating-point numbers to reduce file size\n",
        "    essential_df = essential_df.round({\n",
        "        'latent_x': 4,\n",
        "        'latent_y': 4,\n",
        "        'x': 4,\n",
        "        'y': 4,\n",
        "        'z': 4,\n",
        "        'absmag': 4\n",
        "    })\n",
        "\n",
        "    # 6. Save the DataFrame directly to a gzipped CSV file\n",
        "    essential_df.to_csv(output_path, index=False, compression='gzip')\n",
        "\n",
        "    print(f\"Essential star data saved to '{output_path}'\")\n",
        "\n",
        "export_star_data_to_csv_gz(df_filtered, all_coords, f'/content/drive/MyDrive/Data/{study_name}_front.csv.gz')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}