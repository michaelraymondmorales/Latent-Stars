{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "AJjv8DcPP4T9"
      },
      "outputs": [],
      "source": [
        "# =========================================================================\n",
        "# === NOTEBOOK CONFIGURATION ===\n",
        "# Set this to False to quickly load the best parameters for the autoencoder.\n",
        "# Set this to True to run a full Optuna study to find new best parameters.\n",
        "# RUN_FULL_OPTUNA_STUDY = True\n",
        "# ========================================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJXX-JUSKdp3",
        "outputId": "9f55d21a-abc8-4735-953c-8f6d55674063"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.12/dist-packages (4.5.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.16.5)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.43)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (6.3.0)\n",
            "Requirement already satisfied: narwhals>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from plotly) (2.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from plotly) (25.0)\n",
            "Requirement already satisfied: kaleido in /usr/local/lib/python3.12/dist-packages (1.1.0)\n",
            "Requirement already satisfied: choreographer>=1.0.10 in /usr/local/lib/python3.12/dist-packages (from kaleido) (1.1.1)\n",
            "Requirement already satisfied: logistro>=1.0.8 in /usr/local/lib/python3.12/dist-packages (from kaleido) (1.1.0)\n",
            "Requirement already satisfied: orjson>=3.10.15 in /usr/local/lib/python3.12/dist-packages (from kaleido) (3.11.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kaleido) (25.0)\n",
            "Requirement already satisfied: pytest-timeout>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from kaleido) (2.4.0)\n",
            "Requirement already satisfied: simplejson>=3.19.3 in /usr/local/lib/python3.12/dist-packages (from choreographer>=1.0.10->kaleido) (3.20.1)\n",
            "Requirement already satisfied: pytest>=7.0.0 in /usr/local/lib/python3.12/dist-packages (from pytest-timeout>=2.4.0->kaleido) (8.4.2)\n",
            "Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.12/dist-packages (from pytest>=7.0.0->pytest-timeout>=2.4.0->kaleido) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.12/dist-packages (from pytest>=7.0.0->pytest-timeout>=2.4.0->kaleido) (1.6.0)\n",
            "Requirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from pytest>=7.0.0->pytest-timeout>=2.4.0->kaleido) (2.19.2)\n",
            "\n",
            "Plotly will install a copy of Google Chrome to be used for generating static images of plots.\n",
            "Chrome will be installed at: None\n",
            "Do you want to proceed? [y/n] y\n",
            "Installing Chrome for Plotly...\n",
            "Chrome installed successfully.\n",
            "The Chrome executable is now located at: /usr/local/lib/python3.12/dist-packages/choreographer/cli/browser_exe/chrome-linux64/chrome\n"
          ]
        }
      ],
      "source": [
        "!pip install -U optuna\n",
        "!pip install -U plotly\n",
        "!pip install -U kaleido\n",
        "!plotly_get_chrome\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import gzip\n",
        "import json\n",
        "import io\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import optuna\n",
        "from plotly.io import show\n",
        "from datetime import datetime\n",
        "from optuna.trial import TrialState\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K258Fig6RR22",
        "outputId": "5287d78a-a7e4-444a-e8e8-f027563c85a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting data pipeline: Attempting to download HYG star data...\n",
            "Trying URL: https://codeberg.org/astronexus/hyg/media/branch/main/data/hyg/CURRENT/hyg_v42.csv.gz\n",
            "Download successful.\n"
          ]
        }
      ],
      "source": [
        "# --- Dataset Download  ---\n",
        "def download_hyg_dataset():\n",
        "    \"\"\"\n",
        "    Attempts to download the gzipped CSV file from a list of URLs.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A pandas DataFrame of the HYG data if successful, None otherwise.\n",
        "    \"\"\"\n",
        "    # URLs to official public HYG data set repository and backup copy hosted on Google Drive.\n",
        "    HYG_URLS = ['https://codeberg.org/astronexus/hyg/media/branch/main/data/hyg/CURRENT/hyg_v42.csv.gz',\n",
        "                'https://drive.google.com/uc?export=download&id=1U2apsUPjQR_DllzF74y-pV3KjVTK3FJW']\n",
        "\n",
        "    hyg_file = None\n",
        "    print(\"\\nStarting data pipeline: Attempting to download HYG star data...\")\n",
        "\n",
        "    for url in HYG_URLS:\n",
        "        try:\n",
        "            print(f\"Trying URL: {url}\")\n",
        "            response = requests.get(url, timeout=30)\n",
        "            response.raise_for_status()\n",
        "            hyg_file = io.BytesIO(response.content)\n",
        "            hyg_df = pd.read_csv(hyg_file, compression='gzip')\n",
        "            print(\"Download successful.\")\n",
        "            return hyg_df\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error downloading from {url}: {e}\")\n",
        "            print(\"Trying next URL...\")\n",
        "        except Exception as e:\n",
        "            print(f\"An unexpected error occurred during data processing: {e}\")\n",
        "            return None\n",
        "\n",
        "    print(\"\\nAll download attempts failed. Please check your internet connection or the URLs.\")\n",
        "    return None\n",
        "\n",
        "# Download the data\n",
        "df = download_hyg_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByPuNT8QQtOB",
        "outputId": "dbe5dc8a-521f-4164-c353-28b78671c07d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- HYG Dataset Head (First 5 Rows) ---\n",
            "   id  hip        hd  hr   gl   bf proper        ra        dec      dist  \\\n",
            "0   0  NaN       NaN NaN  NaN  NaN    Sol  0.000000   0.000000    0.0000   \n",
            "1   1  1.0  224700.0 NaN  NaN  NaN    NaN  0.000060   1.089009  219.7802   \n",
            "2   2  2.0  224690.0 NaN  NaN  NaN    NaN  0.000283 -19.498840   47.9616   \n",
            "3   3  3.0  224699.0 NaN  NaN  NaN    NaN  0.000335  38.859279  442.4779   \n",
            "4   4  4.0  224707.0 NaN  NaN  NaN    NaN  0.000569 -51.893546  134.2282   \n",
            "\n",
            "     pmra  pmdec   rv    mag  absmag spect     ci           x         y  \\\n",
            "0    0.00   0.00  0.0 -26.70   4.850   G2V  0.656    0.000005  0.000000   \n",
            "1   -5.20  -1.88  0.0   9.10   2.390    F5  0.482  219.740502  0.003449   \n",
            "2  181.21  -0.93  0.0   9.27   5.866   K3V  0.999   45.210918  0.003365   \n",
            "3    5.24  -2.91  0.0   6.61  -1.619    B9 -0.019  344.552785  0.030213   \n",
            "4   62.85   0.16  0.0   8.06   2.421   F0V  0.370   82.835513  0.012476   \n",
            "\n",
            "            z            vx        vy            vz     rarad    decrad  \\\n",
            "0    0.000000  0.000000e+00  0.000000  0.000000e+00  0.000000  0.000000   \n",
            "1    4.177065  4.000000e-08 -0.000006 -2.000000e-06  0.000016  0.019007   \n",
            "2  -16.008996 -7.000000e-08  0.000042 -2.000000e-07  0.000074 -0.340319   \n",
            "3  277.614965  3.920000e-06  0.000011 -4.860000e-06  0.000088  0.678222   \n",
            "4 -105.619540  8.000000e-08  0.000041  6.000000e-08  0.000149 -0.905713   \n",
            "\n",
            "        pmrarad      pmdecrad bayer  flam  con  comp  comp_primary base  \\\n",
            "0  0.000000e+00  0.000000e+00   NaN   NaN  NaN     1             0  NaN   \n",
            "1 -2.521031e-08 -9.114497e-09   NaN   NaN  Psc     1             1  NaN   \n",
            "2  8.785309e-07 -4.508767e-09   NaN   NaN  Cet     1             2  NaN   \n",
            "3  2.540424e-08 -1.410808e-08   NaN   NaN  And     1             3  NaN   \n",
            "4  3.047054e-07  7.757010e-10   NaN   NaN  Phe     1             4  NaN   \n",
            "\n",
            "          lum  var  var_min  var_max  \n",
            "0    1.000000  NaN      NaN      NaN  \n",
            "1    9.638290  NaN      NaN      NaN  \n",
            "2    0.392283  NaN      NaN      NaN  \n",
            "3  386.901132  NaN      NaN      NaN  \n",
            "4    9.366989  NaN      NaN      NaN  \n",
            "\n",
            "--- Dataset Info ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 119626 entries, 0 to 119625\n",
            "Data columns (total 37 columns):\n",
            " #   Column        Non-Null Count   Dtype  \n",
            "---  ------        --------------   -----  \n",
            " 0   id            119626 non-null  int64  \n",
            " 1   hip           117951 non-null  float64\n",
            " 2   hd            98885 non-null   float64\n",
            " 3   hr            9041 non-null    float64\n",
            " 4   gl            3801 non-null    object \n",
            " 5   bf            3099 non-null    object \n",
            " 6   proper        499 non-null     object \n",
            " 7   ra            119626 non-null  float64\n",
            " 8   dec           119626 non-null  float64\n",
            " 9   dist          119626 non-null  float64\n",
            " 10  pmra          119626 non-null  float64\n",
            " 11  pmdec         119626 non-null  float64\n",
            " 12  rv            119626 non-null  float64\n",
            " 13  mag           119626 non-null  float64\n",
            " 14  absmag        119626 non-null  float64\n",
            " 15  spect         116578 non-null  object \n",
            " 16  ci            117735 non-null  float64\n",
            " 17  x             119626 non-null  float64\n",
            " 18  y             119626 non-null  float64\n",
            " 19  z             119626 non-null  float64\n",
            " 20  vx            119626 non-null  float64\n",
            " 21  vy            119626 non-null  float64\n",
            " 22  vz            119626 non-null  float64\n",
            " 23  rarad         119626 non-null  float64\n",
            " 24  decrad        119626 non-null  float64\n",
            " 25  pmrarad       119626 non-null  float64\n",
            " 26  pmdecrad      119626 non-null  float64\n",
            " 27  bayer         1537 non-null    object \n",
            " 28  flam          2737 non-null    float64\n",
            " 29  con           119625 non-null  object \n",
            " 30  comp          119626 non-null  int64  \n",
            " 31  comp_primary  119626 non-null  int64  \n",
            " 32  base          1086 non-null    object \n",
            " 33  lum           119626 non-null  float64\n",
            " 34  var           5992 non-null    object \n",
            " 35  var_min       16991 non-null   float64\n",
            " 36  var_max       16991 non-null   float64\n",
            "dtypes: float64(26), int64(3), object(8)\n",
            "memory usage: 33.8+ MB\n",
            "\n",
            "There are 4309 unique spectral types in the dataset.\n",
            "\n",
            "--- Rarest Spectral Types Sample ---\n",
            "spect\n",
            "G0Iab         1\n",
            "G5IIIp        1\n",
            "A4/A7:m...    1\n",
            "F5Ib/II       1\n",
            "B2IIn...      1\n",
            "DAe           1\n",
            "F5V: + F      1\n",
            "O9.5Iab-Ib    1\n",
            "B4:V:ne       1\n",
            "M0III SB      1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Number of spectral types that appear only once: 2401\n",
            "Number of spectral types that appear only twice: 567\n"
          ]
        }
      ],
      "source": [
        "# --- Dataset Inspection ---\n",
        "# Set pandas display options to see all columns\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "print(\"\\n--- HYG Dataset Head (First 5 Rows) ---\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\n--- Dataset Info ---\")\n",
        "df.info()\n",
        "\n",
        "unique_spect_count = df['spect'].nunique(dropna=True)\n",
        "print(f\"\\nThere are {unique_spect_count} unique spectral types in the dataset.\")\n",
        "\n",
        "# Count the occurrences of each spectral type\n",
        "spect_counts = df['spect'].value_counts()\n",
        "\n",
        "# This will show spectral types with the lowest counts\n",
        "rarest_spect_types = spect_counts.tail(10)\n",
        "print(\"\\n--- Rarest Spectral Types Sample ---\")\n",
        "print(rarest_spect_types)\n",
        "\n",
        "# Get a summary of how many types appear only a few times\n",
        "types_with_one_occurrence = (spect_counts == 1).sum()\n",
        "types_with_two_occurrences = (spect_counts == 2).sum()\n",
        "\n",
        "print(f\"\\nNumber of spectral types that appear only once: {types_with_one_occurrence}\")\n",
        "print(f\"Number of spectral types that appear only twice: {types_with_two_occurrences}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfLqaPbu9hFk",
        "outputId": "81ecadb4-a76b-403a-8554-c1ebff0771d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset size: 119626\n",
            "Filtered dataset size after dropping rows with missing features: 115368\n",
            "\n",
            "There are 4222 unique spectral types after filtering.\n",
            "\n",
            "Training set size: 92294 samples\n",
            "Validation set size: 23074 samples\n"
          ]
        }
      ],
      "source": [
        "# --- 2. Data Preprocessing and Feature Selection ---\n",
        "\n",
        "print(f\"Original dataset size: {len(df)}\")\n",
        "\n",
        "# For simplicity, only use stars with non-null values for the chosen features.\n",
        "features = ['absmag', 'ci', 'spect']\n",
        "df_filtered = df.dropna(subset=features)\n",
        "print(f\"Filtered dataset size after dropping rows with missing features: {len(df_filtered)}\")\n",
        "\n",
        "# Prepare numerical and categorical data\n",
        "numerical_features = df_filtered[['absmag', 'ci']]\n",
        "categorical_features = df_filtered['spect']\n",
        "\n",
        "# Convert the categorical 'spect' column into numerical indices\n",
        "# This is a critical step for using an embedding layer\n",
        "spect_encoded, unique_spects = pd.factorize(categorical_features)\n",
        "NUM_SPECT_TYPES = len(unique_spects)\n",
        "print(f\"\\nThere are {NUM_SPECT_TYPES} unique spectral types after filtering.\")\n",
        "\n",
        "# We also need the IDs and star names for our final JSON export\n",
        "star_info = df_filtered[['id', 'proper', 'gl', 'hip']]\n",
        "\n",
        "# Scale the numerical features\n",
        "scaler = StandardScaler()\n",
        "scaled_numerical_features = scaler.fit_transform(numerical_features)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "# We split the numerical features, the encoded spectral types, and the star info\n",
        "X_num_train, X_num_val, X_cat_train, X_cat_val, star_info_train, star_info_val = train_test_split(\n",
        "    scaled_numerical_features, spect_encoded, star_info, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert the NumPy arrays to PyTorch tensors\n",
        "X_num_train = torch.tensor(X_num_train, dtype=torch.float32)\n",
        "X_num_val = torch.tensor(X_num_val, dtype=torch.float32)\n",
        "# Ensure categorical tensor is of long type\n",
        "X_cat_train = torch.tensor(X_cat_train, dtype=torch.long)\n",
        "X_cat_val = torch.tensor(X_cat_val, dtype=torch.long)\n",
        "\n",
        "# Create TensorDatasets for training and validation\n",
        "# Note that we are passing both the numerical and categorical tensors\n",
        "train_dataset = TensorDataset(X_num_train, X_cat_train)\n",
        "val_dataset = TensorDataset(X_num_val, X_cat_val)\n",
        "\n",
        "# Create DataLoaders for training and validation\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "print(f\"\\nTraining set size: {len(X_num_train)} samples\")\n",
        "print(f\"Validation set size: {len(X_num_val)} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "5A-IIDU8zgpQ"
      },
      "outputs": [],
      "source": [
        "def print_model_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the name and shape of each parameter in a PyTorch model.\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Model Parameters ---\")\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            print(f\"Layer: {name:<25} | Shape: {list(param.shape)}\")\n",
        "    print(\"------------------------\\n\")\n",
        "\n",
        "def save_checkpoint(trial, model, best_val_loss, file_path):\n",
        "    \"\"\"\n",
        "    Saves a dictionary containing the model's state, hyperparameters, and trial info.\n",
        "\n",
        "    Args:\n",
        "        trial (optuna.trial.Trial): The current Optuna trial object.\n",
        "        model (torch.nn.Module): The model to save.\n",
        "        best_val_loss (float): The best validation loss achieved so far.\n",
        "        file_path (str): The full path for the checkpoint file.\n",
        "    \"\"\"\n",
        "    # Create the checkpoint dictionary\n",
        "    checkpoint = {\n",
        "        'trial_number': trial.number,\n",
        "        'hyperparameters': trial.params,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'val_loss': best_val_loss\n",
        "    }\n",
        "\n",
        "    # Save the checkpoint to a uniquely named file\n",
        "    torch.save(checkpoint, file_path)\n",
        "    print(f\"Checkpoint saved for Trial {trial.number} with a new best Val Loss of {best_val_loss:.4f} to {file_path}\")\n",
        "\n",
        "def save_study_metadata(study: optuna.study.Study, file_path: str):\n",
        "    \"\"\"\n",
        "    Saves the metadata of an Optuna study to a JSON file.\n",
        "\n",
        "    Args:\n",
        "        study (optuna.study.Study): The Optuna study object to save.\n",
        "        file_path (str): The full path to the output JSON file in Google Drive.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Get the current time for the log\n",
        "        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "        # Extract essential information from the best trial\n",
        "        best_trial = study.best_trial\n",
        "        best_params = best_trial.params\n",
        "        best_value = best_trial.value\n",
        "\n",
        "        # Create a dictionary to hold the metadata\n",
        "        metadata = {\n",
        "            \"study_name\": study.study_name,\n",
        "            \"timestamp\": timestamp,\n",
        "            \"best_value\": best_value,\n",
        "            \"best_params\": best_params,\n",
        "            \"state\": str(study.best_trial.state),\n",
        "            \"user_attributes\": study.best_trial.user_attrs,\n",
        "            \"study_direction\": str(study.direction),\n",
        "            \"trials_completed\": len(study.trials)\n",
        "        }\n",
        "\n",
        "        # Convert the dictionary to a JSON string\n",
        "        json_metadata = json.dumps(metadata, indent=4, sort_keys=True)\n",
        "\n",
        "        # Write the JSON string to the specified file\n",
        "        with open(file_path, 'w') as f:\n",
        "            f.write(json_metadata)\n",
        "\n",
        "        print(f\"Study metadata successfully saved to: {file_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while saving study metadata: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "mG9rQol69XDG"
      },
      "outputs": [],
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_numerical_features: int,\n",
        "                 num_spect_types: int,\n",
        "                 spect_embedding_dim: int,\n",
        "                 n_encoder_layers: int,\n",
        "                 n_hidden_neurons: int,\n",
        "                 dropout_rate: float,\n",
        "                 latent_dim: int=3):\n",
        "\n",
        "        super(Autoencoder, self).__init__()\n",
        "\n",
        "        # Save these for the forward pass\n",
        "        self.num_numerical_features = num_numerical_features\n",
        "        self.spect_embedding_dim = spect_embedding_dim\n",
        "        self.num_spect_types = num_spect_types\n",
        "\n",
        "        # Define the embedding layer for the spectral types\n",
        "        self.spect_embedding = nn.Embedding(num_embeddings=num_spect_types, embedding_dim=spect_embedding_dim)\n",
        "\n",
        "        # Calculate the total input dimension after embedding\n",
        "        total_input_dim = num_numerical_features + spect_embedding_dim\n",
        "\n",
        "        # Dynamically build the encoder\n",
        "        encoder_layers = []\n",
        "        # Store layer dimensions to mirror in the decoder\n",
        "        layer_dims = [total_input_dim]\n",
        "        for i in range(n_encoder_layers):\n",
        "            next_dim = n_hidden_neurons // (2**i) if i < n_encoder_layers - 1 else latent_dim\n",
        "            encoder_layers.append(nn.Linear(layer_dims[-1], next_dim))\n",
        "            encoder_layers.append(nn.ReLU())\n",
        "            encoder_layers.append(nn.Dropout(dropout_rate))\n",
        "            layer_dims.append(next_dim)\n",
        "        self.encoder = nn.Sequential(*encoder_layers)\n",
        "\n",
        "        # Dynamically build the decoder by reversing the layer dimensions\n",
        "        decoder_layers = []\n",
        "        reversed_dims = list(reversed(layer_dims))\n",
        "        for i in range(len(reversed_dims) - 1):\n",
        "            decoder_layers.append(nn.Linear(reversed_dims[i], reversed_dims[i+1]))\n",
        "            # Add ReLU for all but the final layer\n",
        "            if i < len(reversed_dims) - 2:\n",
        "                decoder_layers.append(nn.ReLU())\n",
        "\n",
        "        self.decoder = nn.Sequential(*decoder_layers)\n",
        "\n",
        "        # Add final layers for reconstructing numerical and categorical features\n",
        "        # The decoder's last output is `total_input_dim`, so we split it here\n",
        "        self.reconstruct_numerical = nn.Linear(total_input_dim, num_numerical_features)\n",
        "        self.reconstruct_categorical = nn.Linear(total_input_dim, num_spect_types)\n",
        "\n",
        "    def forward(self, x_num, x_cat):\n",
        "        # 1. Pass the categorical features through the embedding layer\n",
        "        x_cat_embedded = self.spect_embedding(x_cat)\n",
        "\n",
        "        # 2. Concatenate the numerical and embedded categorical features\n",
        "        x_combined = torch.cat((x_num, x_cat_embedded), dim=1)\n",
        "\n",
        "        # 3. Pass the combined tensor through the encoder to get the latent representation\n",
        "        latent_coords = self.encoder(x_combined)\n",
        "\n",
        "        # 4. Pass the latent representation through the decoder to get a reconstruction\n",
        "        reconstruction = self.decoder(latent_coords)\n",
        "\n",
        "        # 5. Separate the reconstructed output into numerical and categorical parts\n",
        "        reconstructed_num = self.reconstruct_numerical(reconstruction)\n",
        "        reconstructed_cat_logits = self.reconstruct_categorical(reconstruction)\n",
        "\n",
        "        return latent_coords, reconstructed_num, reconstructed_cat_logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OD6tlfuS9p4x",
        "outputId": "7812be3d-3d9c-48e4-eebe-76f1d9d8daf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU not available, using CPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-09-22 00:10:39,418] Using an existing study with name 'AE_StellarParams_Latent_Wide_r3' instead of creating a new one.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Model Parameters ---\n",
            "Layer: spect_embedding.weight    | Shape: [4222, 54]\n",
            "Layer: encoder.0.weight          | Shape: [256, 56]\n",
            "Layer: encoder.0.bias            | Shape: [256]\n",
            "Layer: encoder.3.weight          | Shape: [128, 256]\n",
            "Layer: encoder.3.bias            | Shape: [128]\n",
            "Layer: encoder.6.weight          | Shape: [64, 128]\n",
            "Layer: encoder.6.bias            | Shape: [64]\n",
            "Layer: encoder.9.weight          | Shape: [3, 64]\n",
            "Layer: encoder.9.bias            | Shape: [3]\n",
            "Layer: decoder.0.weight          | Shape: [64, 3]\n",
            "Layer: decoder.0.bias            | Shape: [64]\n",
            "Layer: decoder.2.weight          | Shape: [128, 64]\n",
            "Layer: decoder.2.bias            | Shape: [128]\n",
            "Layer: decoder.4.weight          | Shape: [256, 128]\n",
            "Layer: decoder.4.bias            | Shape: [256]\n",
            "Layer: decoder.6.weight          | Shape: [56, 256]\n",
            "Layer: decoder.6.bias            | Shape: [56]\n",
            "Layer: reconstruct_numerical.weight | Shape: [2, 56]\n",
            "Layer: reconstruct_numerical.bias | Shape: [2]\n",
            "Layer: reconstruct_categorical.weight | Shape: [4222, 56]\n",
            "Layer: reconstruct_categorical.bias | Shape: [4222]\n",
            "------------------------\n",
            "\n",
            "Checkpoint saved for Trial 96 with a new best Val Loss of 0.3114 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_96_best.pth\n",
            "Trial 96, Epoch [1/100], Val Loss: 0.3114\n",
            "Checkpoint saved for Trial 96 with a new best Val Loss of 0.2349 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_96_best.pth\n",
            "Trial 96, Epoch [2/100], Val Loss: 0.2349\n",
            "Checkpoint saved for Trial 96 with a new best Val Loss of 0.1874 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_96_best.pth\n",
            "Trial 96, Epoch [3/100], Val Loss: 0.1874\n",
            "Trial 96, Epoch [4/100], Val Loss: 0.1933\n",
            "Checkpoint saved for Trial 96 with a new best Val Loss of 0.1749 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_96_best.pth\n",
            "Trial 96, Epoch [5/100], Val Loss: 0.1749\n",
            "Checkpoint saved for Trial 96 with a new best Val Loss of 0.1667 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_96_best.pth\n",
            "Trial 96, Epoch [6/100], Val Loss: 0.1667\n",
            "Checkpoint saved for Trial 96 with a new best Val Loss of 0.1608 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_96_best.pth\n",
            "Trial 96, Epoch [7/100], Val Loss: 0.1608\n",
            "Checkpoint saved for Trial 96 with a new best Val Loss of 0.1546 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_96_best.pth\n",
            "Trial 96, Epoch [8/100], Val Loss: 0.1546\n",
            "Checkpoint saved for Trial 96 with a new best Val Loss of 0.1474 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_96_best.pth\n",
            "Trial 96, Epoch [9/100], Val Loss: 0.1474\n",
            "Trial 96, Epoch [10/100], Val Loss: 0.1498\n",
            "Checkpoint saved for Trial 96 with a new best Val Loss of 0.1431 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_96_best.pth\n",
            "Trial 96, Epoch [11/100], Val Loss: 0.1431\n",
            "Checkpoint saved for Trial 96 with a new best Val Loss of 0.1391 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_96_best.pth\n",
            "Trial 96, Epoch [12/100], Val Loss: 0.1391\n",
            "Trial 96, Epoch [13/100], Val Loss: 0.1434\n",
            "Trial 96, Epoch [14/100], Val Loss: 0.1515\n",
            "Checkpoint saved for Trial 96 with a new best Val Loss of 0.1375 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_96_best.pth\n",
            "Trial 96, Epoch [15/100], Val Loss: 0.1375\n",
            "Trial 96, Epoch [16/100], Val Loss: 0.1381\n",
            "Checkpoint saved for Trial 96 with a new best Val Loss of 0.1330 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_96_best.pth\n",
            "Trial 96, Epoch [17/100], Val Loss: 0.1330\n",
            "Trial 96, Epoch [18/100], Val Loss: 0.1348\n",
            "Trial 96, Epoch [19/100], Val Loss: 0.1360\n",
            "Trial 96, Epoch [20/100], Val Loss: 0.1337\n",
            "Checkpoint saved for Trial 96 with a new best Val Loss of 0.1302 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_96_best.pth\n",
            "Trial 96, Epoch [21/100], Val Loss: 0.1302\n",
            "Trial 96, Epoch [22/100], Val Loss: 0.1336\n",
            "Trial 96, Epoch [23/100], Val Loss: 0.1401\n",
            "Checkpoint saved for Trial 96 with a new best Val Loss of 0.1250 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_96_best.pth\n",
            "Trial 96, Epoch [24/100], Val Loss: 0.1250\n",
            "Trial 96, Epoch [25/100], Val Loss: 0.1292\n",
            "Trial 96, Epoch [26/100], Val Loss: 0.1279\n",
            "Checkpoint saved for Trial 96 with a new best Val Loss of 0.1239 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_96_best.pth\n",
            "Trial 96, Epoch [27/100], Val Loss: 0.1239\n",
            "Trial 96, Epoch [28/100], Val Loss: 0.1265\n",
            "Trial 96, Epoch [29/100], Val Loss: 0.1261\n",
            "Trial 96, Epoch [30/100], Val Loss: 0.1278\n",
            "Trial 96, Epoch [31/100], Val Loss: 0.1283\n",
            "Trial 96, Epoch [32/100], Val Loss: 0.1246\n",
            "Checkpoint saved for Trial 96 with a new best Val Loss of 0.1210 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_96_best.pth\n",
            "Trial 96, Epoch [33/100], Val Loss: 0.1210\n",
            "Trial 96, Epoch [34/100], Val Loss: 0.1248\n",
            "Trial 96, Epoch [35/100], Val Loss: 0.1211\n",
            "Trial 96, Epoch [36/100], Val Loss: 0.1275\n",
            "Trial 96, Epoch [37/100], Val Loss: 0.1241\n",
            "Trial 96, Epoch [38/100], Val Loss: 0.1220\n",
            "Trial 96, Epoch [39/100], Val Loss: 0.1227\n",
            "Checkpoint saved for Trial 96 with a new best Val Loss of 0.1203 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_96_best.pth\n",
            "Trial 96, Epoch [40/100], Val Loss: 0.1203\n",
            "Checkpoint saved for Trial 96 with a new best Val Loss of 0.1187 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_96_best.pth\n",
            "Trial 96, Epoch [41/100], Val Loss: 0.1187\n",
            "Checkpoint saved for Trial 96 with a new best Val Loss of 0.1184 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_96_best.pth\n",
            "Trial 96, Epoch [42/100], Val Loss: 0.1184\n",
            "Trial 96, Epoch [43/100], Val Loss: 0.1197\n",
            "Trial 96, Epoch [44/100], Val Loss: 0.1217\n",
            "Checkpoint saved for Trial 96 with a new best Val Loss of 0.1163 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_96_best.pth\n",
            "Trial 96, Epoch [45/100], Val Loss: 0.1163\n",
            "Trial 96, Epoch [46/100], Val Loss: 0.1192\n",
            "Trial 96, Epoch [47/100], Val Loss: 0.1185\n",
            "Trial 96, Epoch [48/100], Val Loss: 0.1179\n",
            "Trial 96, Epoch [49/100], Val Loss: 0.1167\n",
            "Trial 96, Epoch [50/100], Val Loss: 0.1176\n",
            "Trial 96, Epoch [51/100], Val Loss: 0.1172\n",
            "Checkpoint saved for Trial 96 with a new best Val Loss of 0.1154 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_96_best.pth\n",
            "Trial 96, Epoch [52/100], Val Loss: 0.1154\n",
            "Trial 96, Epoch [53/100], Val Loss: 0.1182\n",
            "Checkpoint saved for Trial 96 with a new best Val Loss of 0.1153 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_96_best.pth\n",
            "Trial 96, Epoch [54/100], Val Loss: 0.1153\n",
            "Trial 96, Epoch [55/100], Val Loss: 0.1158\n",
            "Trial 96, Epoch [56/100], Val Loss: 0.1159\n",
            "Trial 96, Epoch [57/100], Val Loss: 0.1225\n",
            "Trial 96, Epoch [58/100], Val Loss: 0.1203\n",
            "Trial 96, Epoch [59/100], Val Loss: 0.1160\n",
            "Trial 96, Epoch [60/100], Val Loss: 0.1162\n",
            "Checkpoint saved for Trial 96 with a new best Val Loss of 0.1149 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_96_best.pth\n",
            "Trial 96, Epoch [61/100], Val Loss: 0.1149\n",
            "Trial 96, Epoch [62/100], Val Loss: 0.1210\n",
            "Trial 96, Epoch [63/100], Val Loss: 0.1152\n",
            "Trial 96, Epoch [64/100], Val Loss: 0.1163\n",
            "Checkpoint saved for Trial 96 with a new best Val Loss of 0.1127 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_96_best.pth\n",
            "Trial 96, Epoch [65/100], Val Loss: 0.1127\n",
            "Trial 96, Epoch [66/100], Val Loss: 0.1143\n",
            "Trial 96, Epoch [67/100], Val Loss: 0.1160\n",
            "Trial 96, Epoch [68/100], Val Loss: 0.1179\n",
            "Trial 96, Epoch [69/100], Val Loss: 0.1135\n",
            "Trial 96, Epoch [70/100], Val Loss: 0.1140\n",
            "Checkpoint saved for Trial 96 with a new best Val Loss of 0.1119 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_96_best.pth\n",
            "Trial 96, Epoch [71/100], Val Loss: 0.1119\n",
            "Trial 96, Epoch [72/100], Val Loss: 0.1184\n",
            "Trial 96, Epoch [73/100], Val Loss: 0.1121\n",
            "Checkpoint saved for Trial 96 with a new best Val Loss of 0.1104 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_96_best.pth\n",
            "Trial 96, Epoch [74/100], Val Loss: 0.1104\n",
            "Trial 96, Epoch [75/100], Val Loss: 0.1171\n",
            "Trial 96, Epoch [76/100], Val Loss: 0.1151\n",
            "Trial 96, Epoch [77/100], Val Loss: 0.1131\n",
            "Trial 96, Epoch [78/100], Val Loss: 0.1113\n",
            "Trial 96, Epoch [79/100], Val Loss: 0.1116\n",
            "Trial 96, Epoch [80/100], Val Loss: 0.1106\n",
            "Trial 96, Epoch [81/100], Val Loss: 0.1112\n",
            "Trial 96, Epoch [82/100], Val Loss: 0.1145\n",
            "Trial 96, Epoch [83/100], Val Loss: 0.1147\n",
            "Trial 96, Epoch [84/100], Val Loss: 0.1129\n",
            "Checkpoint saved for Trial 96 with a new best Val Loss of 0.1100 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_96_best.pth\n",
            "Trial 96, Epoch [85/100], Val Loss: 0.1100\n",
            "Trial 96, Epoch [86/100], Val Loss: 0.1109\n",
            "Trial 96, Epoch [87/100], Val Loss: 0.1102\n",
            "Trial 96, Epoch [88/100], Val Loss: 0.1210\n",
            "Trial 96, Epoch [89/100], Val Loss: 0.1117\n",
            "Trial 96, Epoch [90/100], Val Loss: 0.1167\n",
            "Trial 96, Epoch [91/100], Val Loss: 0.1191\n",
            "Trial 96, Epoch [92/100], Val Loss: 0.1127\n",
            "Trial 96, Epoch [93/100], Val Loss: 0.1118\n",
            "Trial 96, Epoch [94/100], Val Loss: 0.1138\n",
            "Checkpoint saved for Trial 96 with a new best Val Loss of 0.1070 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_96_best.pth\n",
            "Trial 96, Epoch [95/100], Val Loss: 0.1070\n",
            "Trial 96, Epoch [96/100], Val Loss: 0.1150\n",
            "Trial 96, Epoch [97/100], Val Loss: 0.1088\n",
            "Trial 96, Epoch [98/100], Val Loss: 0.1096\n",
            "Trial 96, Epoch [99/100], Val Loss: 0.1097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-09-22 01:00:22,734] Trial 96 finished with value: 0.10702821409582597 and parameters: {'learning_rate': 0.0010068565288337352, 'dropout_rate': 0.018291674591159473, 'spect_embedding_dim': 54, 'n_encoder_layers': 4, 'n_hidden_neurons': 256, 'categorical_loss_weight': 0.10681071248767215}. Best is trial 80 with value: 0.0973087496787227.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 96, Epoch [100/100], Val Loss: 0.1105\n",
            "\n",
            "--- Model Parameters ---\n",
            "Layer: spect_embedding.weight    | Shape: [4222, 49]\n",
            "Layer: encoder.0.weight          | Shape: [272, 51]\n",
            "Layer: encoder.0.bias            | Shape: [272]\n",
            "Layer: encoder.3.weight          | Shape: [136, 272]\n",
            "Layer: encoder.3.bias            | Shape: [136]\n",
            "Layer: encoder.6.weight          | Shape: [68, 136]\n",
            "Layer: encoder.6.bias            | Shape: [68]\n",
            "Layer: encoder.9.weight          | Shape: [3, 68]\n",
            "Layer: encoder.9.bias            | Shape: [3]\n",
            "Layer: decoder.0.weight          | Shape: [68, 3]\n",
            "Layer: decoder.0.bias            | Shape: [68]\n",
            "Layer: decoder.2.weight          | Shape: [136, 68]\n",
            "Layer: decoder.2.bias            | Shape: [136]\n",
            "Layer: decoder.4.weight          | Shape: [272, 136]\n",
            "Layer: decoder.4.bias            | Shape: [272]\n",
            "Layer: decoder.6.weight          | Shape: [51, 272]\n",
            "Layer: decoder.6.bias            | Shape: [51]\n",
            "Layer: reconstruct_numerical.weight | Shape: [2, 51]\n",
            "Layer: reconstruct_numerical.bias | Shape: [2]\n",
            "Layer: reconstruct_categorical.weight | Shape: [4222, 51]\n",
            "Layer: reconstruct_categorical.bias | Shape: [4222]\n",
            "------------------------\n",
            "\n",
            "Checkpoint saved for Trial 97 with a new best Val Loss of 0.3249 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_97_best.pth\n",
            "Trial 97, Epoch [1/100], Val Loss: 0.3249\n",
            "Checkpoint saved for Trial 97 with a new best Val Loss of 0.2119 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_97_best.pth\n",
            "Trial 97, Epoch [2/100], Val Loss: 0.2119\n",
            "Checkpoint saved for Trial 97 with a new best Val Loss of 0.1962 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_97_best.pth\n",
            "Trial 97, Epoch [3/100], Val Loss: 0.1962\n",
            "Checkpoint saved for Trial 97 with a new best Val Loss of 0.1933 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_97_best.pth\n",
            "Trial 97, Epoch [4/100], Val Loss: 0.1933\n",
            "Checkpoint saved for Trial 97 with a new best Val Loss of 0.1701 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_97_best.pth\n",
            "Trial 97, Epoch [5/100], Val Loss: 0.1701\n",
            "Checkpoint saved for Trial 97 with a new best Val Loss of 0.1660 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_97_best.pth\n",
            "Trial 97, Epoch [6/100], Val Loss: 0.1660\n",
            "Checkpoint saved for Trial 97 with a new best Val Loss of 0.1554 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_97_best.pth\n",
            "Trial 97, Epoch [7/100], Val Loss: 0.1554\n",
            "Checkpoint saved for Trial 97 with a new best Val Loss of 0.1486 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_97_best.pth\n",
            "Trial 97, Epoch [8/100], Val Loss: 0.1486\n",
            "Trial 97, Epoch [9/100], Val Loss: 0.1507\n",
            "Trial 97, Epoch [10/100], Val Loss: 0.1561\n",
            "Checkpoint saved for Trial 97 with a new best Val Loss of 0.1456 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_97_best.pth\n",
            "Trial 97, Epoch [11/100], Val Loss: 0.1456\n",
            "Checkpoint saved for Trial 97 with a new best Val Loss of 0.1390 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_97_best.pth\n",
            "Trial 97, Epoch [12/100], Val Loss: 0.1390\n",
            "Checkpoint saved for Trial 97 with a new best Val Loss of 0.1364 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_97_best.pth\n",
            "Trial 97, Epoch [13/100], Val Loss: 0.1364\n",
            "Trial 97, Epoch [14/100], Val Loss: 0.1396\n",
            "Checkpoint saved for Trial 97 with a new best Val Loss of 0.1338 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_97_best.pth\n",
            "Trial 97, Epoch [15/100], Val Loss: 0.1338\n",
            "Checkpoint saved for Trial 97 with a new best Val Loss of 0.1295 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_97_best.pth\n",
            "Trial 97, Epoch [16/100], Val Loss: 0.1295\n",
            "Checkpoint saved for Trial 97 with a new best Val Loss of 0.1292 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_97_best.pth\n",
            "Trial 97, Epoch [17/100], Val Loss: 0.1292\n",
            "Trial 97, Epoch [18/100], Val Loss: 0.1319\n",
            "Trial 97, Epoch [19/100], Val Loss: 0.1477\n",
            "Trial 97, Epoch [20/100], Val Loss: 0.1292\n",
            "Trial 97, Epoch [21/100], Val Loss: 0.1317\n",
            "Trial 97, Epoch [22/100], Val Loss: 0.1336\n",
            "Checkpoint saved for Trial 97 with a new best Val Loss of 0.1258 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_97_best.pth\n",
            "Trial 97, Epoch [23/100], Val Loss: 0.1258\n",
            "Trial 97, Epoch [24/100], Val Loss: 0.1345\n",
            "Trial 97, Epoch [25/100], Val Loss: 0.1288\n",
            "Checkpoint saved for Trial 97 with a new best Val Loss of 0.1236 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_97_best.pth\n",
            "Trial 97, Epoch [26/100], Val Loss: 0.1236\n",
            "Checkpoint saved for Trial 97 with a new best Val Loss of 0.1221 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_97_best.pth\n",
            "Trial 97, Epoch [27/100], Val Loss: 0.1221\n",
            "Trial 97, Epoch [28/100], Val Loss: 0.1248\n",
            "Trial 97, Epoch [29/100], Val Loss: 0.1226\n",
            "Trial 97, Epoch [30/100], Val Loss: 0.1260\n",
            "Trial 97, Epoch [31/100], Val Loss: 0.1310\n",
            "Trial 97, Epoch [32/100], Val Loss: 0.1224\n",
            "Checkpoint saved for Trial 97 with a new best Val Loss of 0.1196 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_97_best.pth\n",
            "Trial 97, Epoch [33/100], Val Loss: 0.1196\n",
            "Trial 97, Epoch [34/100], Val Loss: 0.1256\n",
            "Trial 97, Epoch [35/100], Val Loss: 0.1244\n",
            "Trial 97, Epoch [36/100], Val Loss: 0.1221\n",
            "Trial 97, Epoch [37/100], Val Loss: 0.1246\n",
            "Trial 97, Epoch [38/100], Val Loss: 0.1243\n",
            "Checkpoint saved for Trial 97 with a new best Val Loss of 0.1169 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_97_best.pth\n",
            "Trial 97, Epoch [39/100], Val Loss: 0.1169\n",
            "Trial 97, Epoch [40/100], Val Loss: 0.1198\n",
            "Trial 97, Epoch [41/100], Val Loss: 0.1209\n",
            "Trial 97, Epoch [42/100], Val Loss: 0.1228\n",
            "Trial 97, Epoch [43/100], Val Loss: 0.1220\n",
            "Trial 97, Epoch [44/100], Val Loss: 0.1180\n",
            "Checkpoint saved for Trial 97 with a new best Val Loss of 0.1140 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_97_best.pth\n",
            "Trial 97, Epoch [45/100], Val Loss: 0.1140\n",
            "Trial 97, Epoch [46/100], Val Loss: 0.1185\n",
            "Trial 97, Epoch [47/100], Val Loss: 0.1153\n",
            "Trial 97, Epoch [48/100], Val Loss: 0.1207\n",
            "Trial 97, Epoch [49/100], Val Loss: 0.1152\n",
            "Trial 97, Epoch [50/100], Val Loss: 0.1153\n",
            "Trial 97, Epoch [51/100], Val Loss: 0.1224\n",
            "Trial 97, Epoch [52/100], Val Loss: 0.1183\n",
            "Trial 97, Epoch [53/100], Val Loss: 0.1179\n",
            "Trial 97, Epoch [54/100], Val Loss: 0.1161\n",
            "Trial 97, Epoch [55/100], Val Loss: 0.1176\n",
            "Trial 97, Epoch [56/100], Val Loss: 0.1154\n",
            "Trial 97, Epoch [57/100], Val Loss: 0.1145\n",
            "Trial 97, Epoch [58/100], Val Loss: 0.1182\n",
            "Checkpoint saved for Trial 97 with a new best Val Loss of 0.1114 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_97_best.pth\n",
            "Trial 97, Epoch [59/100], Val Loss: 0.1114\n",
            "Trial 97, Epoch [60/100], Val Loss: 0.1183\n",
            "Trial 97, Epoch [61/100], Val Loss: 0.1141\n",
            "Trial 97, Epoch [62/100], Val Loss: 0.1227\n",
            "Trial 97, Epoch [63/100], Val Loss: 0.1170\n",
            "Trial 97, Epoch [64/100], Val Loss: 0.1120\n",
            "Trial 97, Epoch [65/100], Val Loss: 0.1168\n",
            "Trial 97, Epoch [66/100], Val Loss: 0.1116\n",
            "Trial 97, Epoch [67/100], Val Loss: 0.1179\n",
            "Checkpoint saved for Trial 97 with a new best Val Loss of 0.1107 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_97_best.pth\n",
            "Trial 97, Epoch [68/100], Val Loss: 0.1107\n",
            "Trial 97, Epoch [69/100], Val Loss: 0.1122\n",
            "Trial 97, Epoch [70/100], Val Loss: 0.1154\n",
            "Trial 97, Epoch [71/100], Val Loss: 0.1162\n",
            "Trial 97, Epoch [72/100], Val Loss: 0.1132\n",
            "Trial 97, Epoch [73/100], Val Loss: 0.1117\n",
            "Trial 97, Epoch [74/100], Val Loss: 0.1171\n",
            "Trial 97, Epoch [75/100], Val Loss: 0.1185\n",
            "Trial 97, Epoch [76/100], Val Loss: 0.1176\n",
            "Trial 97, Epoch [77/100], Val Loss: 0.1110\n",
            "Trial 97, Epoch [78/100], Val Loss: 0.1153\n",
            "Trial 97, Epoch [79/100], Val Loss: 0.1144\n",
            "Trial 97, Epoch [80/100], Val Loss: 0.1152\n",
            "Checkpoint saved for Trial 97 with a new best Val Loss of 0.1085 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_97_best.pth\n",
            "Trial 97, Epoch [81/100], Val Loss: 0.1085\n",
            "Trial 97, Epoch [82/100], Val Loss: 0.1105\n",
            "Trial 97, Epoch [83/100], Val Loss: 0.1136\n",
            "Trial 97, Epoch [84/100], Val Loss: 0.1123\n",
            "Trial 97, Epoch [85/100], Val Loss: 0.1108\n",
            "Trial 97, Epoch [86/100], Val Loss: 0.1140\n",
            "Trial 97, Epoch [87/100], Val Loss: 0.1133\n",
            "Trial 97, Epoch [88/100], Val Loss: 0.1172\n",
            "Trial 97, Epoch [89/100], Val Loss: 0.1123\n",
            "Trial 97, Epoch [90/100], Val Loss: 0.1109\n",
            "Trial 97, Epoch [91/100], Val Loss: 0.1230\n",
            "Trial 97, Epoch [92/100], Val Loss: 0.1093\n",
            "Trial 97, Epoch [93/100], Val Loss: 0.1126\n",
            "Trial 97, Epoch [94/100], Val Loss: 0.1115\n",
            "Trial 97, Epoch [95/100], Val Loss: 0.1103\n",
            "Trial 97, Epoch [96/100], Val Loss: 0.1119\n",
            "Trial 97, Epoch [97/100], Val Loss: 0.1122\n",
            "Trial 97, Epoch [98/100], Val Loss: 0.1139\n",
            "Trial 97, Epoch [99/100], Val Loss: 0.1132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-09-22 01:44:50,380] Trial 97 finished with value: 0.1084718197181697 and parameters: {'learning_rate': 0.001107246650319292, 'dropout_rate': 0.026066678520000136, 'spect_embedding_dim': 49, 'n_encoder_layers': 4, 'n_hidden_neurons': 272, 'categorical_loss_weight': 0.10698590563430858}. Best is trial 80 with value: 0.0973087496787227.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 97, Epoch [100/100], Val Loss: 0.1144\n",
            "\n",
            "--- Model Parameters ---\n",
            "Layer: spect_embedding.weight    | Shape: [4222, 50]\n",
            "Layer: encoder.0.weight          | Shape: [272, 52]\n",
            "Layer: encoder.0.bias            | Shape: [272]\n",
            "Layer: encoder.3.weight          | Shape: [136, 272]\n",
            "Layer: encoder.3.bias            | Shape: [136]\n",
            "Layer: encoder.6.weight          | Shape: [68, 136]\n",
            "Layer: encoder.6.bias            | Shape: [68]\n",
            "Layer: encoder.9.weight          | Shape: [3, 68]\n",
            "Layer: encoder.9.bias            | Shape: [3]\n",
            "Layer: decoder.0.weight          | Shape: [68, 3]\n",
            "Layer: decoder.0.bias            | Shape: [68]\n",
            "Layer: decoder.2.weight          | Shape: [136, 68]\n",
            "Layer: decoder.2.bias            | Shape: [136]\n",
            "Layer: decoder.4.weight          | Shape: [272, 136]\n",
            "Layer: decoder.4.bias            | Shape: [272]\n",
            "Layer: decoder.6.weight          | Shape: [52, 272]\n",
            "Layer: decoder.6.bias            | Shape: [52]\n",
            "Layer: reconstruct_numerical.weight | Shape: [2, 52]\n",
            "Layer: reconstruct_numerical.bias | Shape: [2]\n",
            "Layer: reconstruct_categorical.weight | Shape: [4222, 52]\n",
            "Layer: reconstruct_categorical.bias | Shape: [4222]\n",
            "------------------------\n",
            "\n",
            "Checkpoint saved for Trial 98 with a new best Val Loss of 0.3341 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_98_best.pth\n",
            "Trial 98, Epoch [1/100], Val Loss: 0.3341\n",
            "Checkpoint saved for Trial 98 with a new best Val Loss of 0.2573 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_98_best.pth\n",
            "Trial 98, Epoch [2/100], Val Loss: 0.2573\n",
            "Checkpoint saved for Trial 98 with a new best Val Loss of 0.2153 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_98_best.pth\n",
            "Trial 98, Epoch [3/100], Val Loss: 0.2153\n",
            "Checkpoint saved for Trial 98 with a new best Val Loss of 0.2079 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_98_best.pth\n",
            "Trial 98, Epoch [4/100], Val Loss: 0.2079\n",
            "Checkpoint saved for Trial 98 with a new best Val Loss of 0.1871 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_98_best.pth\n",
            "Trial 98, Epoch [5/100], Val Loss: 0.1871\n",
            "Checkpoint saved for Trial 98 with a new best Val Loss of 0.1840 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_98_best.pth\n",
            "Trial 98, Epoch [6/100], Val Loss: 0.1840\n",
            "Checkpoint saved for Trial 98 with a new best Val Loss of 0.1804 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_98_best.pth\n",
            "Trial 98, Epoch [7/100], Val Loss: 0.1804\n",
            "Checkpoint saved for Trial 98 with a new best Val Loss of 0.1740 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_98_best.pth\n",
            "Trial 98, Epoch [8/100], Val Loss: 0.1740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-09-22 01:49:53,529] Trial 98 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 98: Pruning trial at epoch 9.\n",
            "\n",
            "--- Model Parameters ---\n",
            "Layer: spect_embedding.weight    | Shape: [4222, 49]\n",
            "Layer: encoder.0.weight          | Shape: [256, 51]\n",
            "Layer: encoder.0.bias            | Shape: [256]\n",
            "Layer: encoder.3.weight          | Shape: [128, 256]\n",
            "Layer: encoder.3.bias            | Shape: [128]\n",
            "Layer: encoder.6.weight          | Shape: [64, 128]\n",
            "Layer: encoder.6.bias            | Shape: [64]\n",
            "Layer: encoder.9.weight          | Shape: [3, 64]\n",
            "Layer: encoder.9.bias            | Shape: [3]\n",
            "Layer: decoder.0.weight          | Shape: [64, 3]\n",
            "Layer: decoder.0.bias            | Shape: [64]\n",
            "Layer: decoder.2.weight          | Shape: [128, 64]\n",
            "Layer: decoder.2.bias            | Shape: [128]\n",
            "Layer: decoder.4.weight          | Shape: [256, 128]\n",
            "Layer: decoder.4.bias            | Shape: [256]\n",
            "Layer: decoder.6.weight          | Shape: [51, 256]\n",
            "Layer: decoder.6.bias            | Shape: [51]\n",
            "Layer: reconstruct_numerical.weight | Shape: [2, 51]\n",
            "Layer: reconstruct_numerical.bias | Shape: [2]\n",
            "Layer: reconstruct_categorical.weight | Shape: [4222, 51]\n",
            "Layer: reconstruct_categorical.bias | Shape: [4222]\n",
            "------------------------\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-09-22 01:50:22,048] Trial 99 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved for Trial 99 with a new best Val Loss of 0.5389 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_99_best.pth\n",
            "Trial 99: Pruning trial at epoch 1.\n",
            "\n",
            "--- Model Parameters ---\n",
            "Layer: spect_embedding.weight    | Shape: [4222, 54]\n",
            "Layer: encoder.0.weight          | Shape: [304, 56]\n",
            "Layer: encoder.0.bias            | Shape: [304]\n",
            "Layer: encoder.3.weight          | Shape: [152, 304]\n",
            "Layer: encoder.3.bias            | Shape: [152]\n",
            "Layer: encoder.6.weight          | Shape: [76, 152]\n",
            "Layer: encoder.6.bias            | Shape: [76]\n",
            "Layer: encoder.9.weight          | Shape: [3, 76]\n",
            "Layer: encoder.9.bias            | Shape: [3]\n",
            "Layer: decoder.0.weight          | Shape: [76, 3]\n",
            "Layer: decoder.0.bias            | Shape: [76]\n",
            "Layer: decoder.2.weight          | Shape: [152, 76]\n",
            "Layer: decoder.2.bias            | Shape: [152]\n",
            "Layer: decoder.4.weight          | Shape: [304, 152]\n",
            "Layer: decoder.4.bias            | Shape: [304]\n",
            "Layer: decoder.6.weight          | Shape: [56, 304]\n",
            "Layer: decoder.6.bias            | Shape: [56]\n",
            "Layer: reconstruct_numerical.weight | Shape: [2, 56]\n",
            "Layer: reconstruct_numerical.bias | Shape: [2]\n",
            "Layer: reconstruct_categorical.weight | Shape: [4222, 56]\n",
            "Layer: reconstruct_categorical.bias | Shape: [4222]\n",
            "------------------------\n",
            "\n",
            "Checkpoint saved for Trial 100 with a new best Val Loss of 0.2527 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_100_best.pth\n",
            "Trial 100, Epoch [1/100], Val Loss: 0.2527\n",
            "Checkpoint saved for Trial 100 with a new best Val Loss of 0.2149 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_100_best.pth\n",
            "Trial 100, Epoch [2/100], Val Loss: 0.2149\n",
            "Trial 100, Epoch [3/100], Val Loss: 0.2240\n",
            "Checkpoint saved for Trial 100 with a new best Val Loss of 0.1790 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_100_best.pth\n",
            "Trial 100, Epoch [4/100], Val Loss: 0.1790\n",
            "Checkpoint saved for Trial 100 with a new best Val Loss of 0.1757 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_100_best.pth\n",
            "Trial 100, Epoch [5/100], Val Loss: 0.1757\n",
            "Trial 100, Epoch [6/100], Val Loss: 0.1810\n",
            "Checkpoint saved for Trial 100 with a new best Val Loss of 0.1620 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_100_best.pth\n",
            "Trial 100, Epoch [7/100], Val Loss: 0.1620\n",
            "Checkpoint saved for Trial 100 with a new best Val Loss of 0.1571 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_100_best.pth\n",
            "Trial 100, Epoch [8/100], Val Loss: 0.1571\n",
            "Trial 100, Epoch [9/100], Val Loss: 0.1573\n",
            "Checkpoint saved for Trial 100 with a new best Val Loss of 0.1500 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_100_best.pth\n",
            "Trial 100, Epoch [10/100], Val Loss: 0.1500\n",
            "Checkpoint saved for Trial 100 with a new best Val Loss of 0.1491 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_100_best.pth\n",
            "Trial 100, Epoch [11/100], Val Loss: 0.1491\n",
            "Trial 100, Epoch [12/100], Val Loss: 0.1516\n",
            "Trial 100, Epoch [13/100], Val Loss: 0.1517\n",
            "Trial 100, Epoch [14/100], Val Loss: 0.1510\n",
            "Checkpoint saved for Trial 100 with a new best Val Loss of 0.1381 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_100_best.pth\n",
            "Trial 100, Epoch [15/100], Val Loss: 0.1381\n",
            "Trial 100, Epoch [16/100], Val Loss: 0.1448\n",
            "Trial 100, Epoch [17/100], Val Loss: 0.1460\n",
            "Trial 100, Epoch [18/100], Val Loss: 0.1433\n",
            "Trial 100, Epoch [19/100], Val Loss: 0.1423\n",
            "Trial 100, Epoch [20/100], Val Loss: 0.1439\n",
            "Checkpoint saved for Trial 100 with a new best Val Loss of 0.1379 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_100_best.pth\n",
            "Trial 100, Epoch [21/100], Val Loss: 0.1379\n",
            "Trial 100, Epoch [22/100], Val Loss: 0.1396\n",
            "Checkpoint saved for Trial 100 with a new best Val Loss of 0.1332 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_100_best.pth\n",
            "Trial 100, Epoch [23/100], Val Loss: 0.1332\n",
            "Trial 100, Epoch [24/100], Val Loss: 0.1359\n",
            "Trial 100, Epoch [25/100], Val Loss: 0.1376\n",
            "Trial 100, Epoch [26/100], Val Loss: 0.1375\n",
            "Checkpoint saved for Trial 100 with a new best Val Loss of 0.1282 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_100_best.pth\n",
            "Trial 100, Epoch [27/100], Val Loss: 0.1282\n",
            "Trial 100, Epoch [28/100], Val Loss: 0.1395\n",
            "Trial 100, Epoch [29/100], Val Loss: 0.1498\n",
            "Trial 100, Epoch [30/100], Val Loss: 0.1375\n",
            "Checkpoint saved for Trial 100 with a new best Val Loss of 0.1260 to /content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_100_best.pth\n",
            "Trial 100, Epoch [31/100], Val Loss: 0.1260\n",
            "Trial 100, Epoch [32/100], Val Loss: 0.1382\n",
            "Trial 100, Epoch [33/100], Val Loss: 0.1306\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-09-22 02:04:36,784] Trial 100 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 100: Pruning trial at epoch 34.\n",
            "Study metadata successfully saved to: /content/drive/MyDrive/Logs/AE_StellarParams_Latent_Wide_r3.json\n"
          ]
        }
      ],
      "source": [
        "# --- 5. Main Execution and Export ---\n",
        "def objective(trial, device, study_name):\n",
        "\n",
        "    # Hyperparameters to be tuned by Optuna\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-1, log=True)\n",
        "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.0, 0.15)\n",
        "    spect_embedding_dim = trial.suggest_int(\"spect_embedding_dim\", 48, 96)\n",
        "    n_encoder_layers = trial.suggest_int(\"n_encoder_layers\", 4, 5)\n",
        "    n_hidden_neurons = trial.suggest_int(\"n_hidden_neurons\", 128, 320, step=16)\n",
        "    categorical_loss_weight = trial.suggest_float(\"categorical_loss_weight\", 0.1, 0.4, log=True)\n",
        "\n",
        "    # Define the model with the suggested hyperparameters\n",
        "    model = Autoencoder(\n",
        "            num_numerical_features=2,  # 'absmag' and 'ci'\n",
        "            num_spect_types=NUM_SPECT_TYPES, # From the preprocessing step\n",
        "            spect_embedding_dim=spect_embedding_dim,\n",
        "            n_encoder_layers=n_encoder_layers,\n",
        "            n_hidden_neurons=n_hidden_neurons,\n",
        "            dropout_rate=dropout_rate\n",
        "            ).to(device)\n",
        "\n",
        "    # Define the optimizer and scheduler\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='min',\n",
        "    factor=0.5,\n",
        "    patience=20)\n",
        "\n",
        "    print_model_parameters(model)\n",
        "\n",
        "    # Training Loop with Early Stopping\n",
        "    patience = 25\n",
        "    epochs_no_improve = 0\n",
        "    best_val_loss = float('inf')\n",
        "    epochs = 100 # Set a reasonable max number of epochs per trial\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        for x_num, x_cat in train_dataloader:\n",
        "            x_num = x_num.to(device)\n",
        "            x_cat = x_cat.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Corrected forward pass with new returns\n",
        "            latent_coords, reconstructed_num, reconstructed_cat_logits = model(x_num, x_cat)\n",
        "\n",
        "            # Use MSE for numerical and CrossEntropy for categorical\n",
        "            # Cross-Entropy expects logits as input and integer labels as target\n",
        "            numerical_loss = F.mse_loss(x_num, reconstructed_num)\n",
        "            categorical_loss = F.cross_entropy(reconstructed_cat_logits, x_cat)\n",
        "\n",
        "            loss = numerical_loss + categorical_loss_weight * categorical_loss\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        total_val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for x_num, x_cat in val_dataloader:\n",
        "                x_num = x_num.to(device)\n",
        "                x_cat = x_cat.to(device)\n",
        "\n",
        "                # Corrected forward pass with new returns\n",
        "                latent_coords, reconstructed_num, reconstructed_cat_logits = model(x_num, x_cat)\n",
        "\n",
        "                numerical_loss = F.mse_loss(x_num, reconstructed_num)\n",
        "                categorical_loss = F.cross_entropy(reconstructed_cat_logits, x_cat)\n",
        "\n",
        "                loss = numerical_loss + categorical_loss_weight * categorical_loss\n",
        "                total_val_loss += loss.item()\n",
        "\n",
        "        avg_val_loss = total_val_loss / len(val_dataloader)\n",
        "\n",
        "        # Early Stopping and Pruning\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            epochs_no_improve = 0\n",
        "            checkpoint_path = f'/content/drive/MyDrive/Checkpoints/{study_name}_trial_{trial.number}_best.pth'\n",
        "            os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
        "            save_checkpoint(trial, model, best_val_loss, checkpoint_path)\n",
        "\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                print(f\"Trial {trial.number}: Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "        # Report the loss to Optuna\n",
        "        trial.report(avg_val_loss, epoch)\n",
        "\n",
        "        # Prune the trial if it's not performing well\n",
        "        if trial.should_prune():\n",
        "            print(f\"Trial {trial.number}: Pruning trial at epoch {epoch + 1}.\")\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "        print(f\"Trial {trial.number}, Epoch [{epoch + 1}/{epochs}], Val Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "    return best_val_loss\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    study_name = 'AE_StellarParams_Latent_Wide_r3'\n",
        "    # 1. Set up the device (CPU or GPU)\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device('cuda')\n",
        "        print('GPU is available and will be used.')\n",
        "    else:\n",
        "        device = torch.device('cpu')\n",
        "        print('GPU not available, using CPU.')\n",
        "    # 1. Hyperparameter Tuning with Optuna\n",
        "    # This will find the best hyperparameters by running multiple trials.\n",
        "    # The 'objective' function is defined separately and contains the training loop.\n",
        "    study = optuna.create_study(\n",
        "            direction='minimize',\n",
        "            storage=f'sqlite:////content/drive/MyDrive/Data/{study_name}.db',\n",
        "            study_name=f'{study_name}',\n",
        "            load_if_exists=True)\n",
        "    study.optimize(lambda trial: objective(trial, device, study_name), n_trials=5)\n",
        "\n",
        "    # Call the function to save the metadata\n",
        "    output_path = f'/content/drive/MyDrive/Logs/{study_name}.json'\n",
        "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "    save_study_metadata(study, output_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VIAB8LsyVa2R",
        "outputId": "ff4759a2-7759-403f-acf6-34802f7addc7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-3.1.0.min.js\" integrity=\"sha256-Ei4740bWZhaUTQuD6q9yQlgVCMPBz6CZWhevDYPv93A=\" crossorigin=\"anonymous\"></script>                <div id=\"306364cd-ac17-43dc-849c-e8a63d6a1043\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById(\"306364cd-ac17-43dc-849c-e8a63d6a1043\")) {                    Plotly.newPlot(                        \"306364cd-ac17-43dc-849c-e8a63d6a1043\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,11,15,29,32,33,34,35,44,46,58,61,62,67,68,69,70,72,73,77,78,80,81,85,86,88,93,94,96,97],\"y\":[0.9043373805664253,2.039987219667831,0.2098351738665903,0.2276665460823976,2.239831152054742,0.193150764129994,0.1736515460128269,0.11977260347734363,0.1438849911950219,0.1349963416033257,0.14696664090714626,0.13620597945521082,0.12541768039445136,0.1248980195537581,0.133001663817552,0.13364940535514475,0.13269867791879375,0.13177704688295763,0.10950503008146036,0.10814355929327969,0.09946178918358692,0.10505637770823081,0.1098959349312528,0.10926721508710173,0.09955605338753261,0.0973087496787227,0.11824671927210037,0.109504919999648,0.11309998444284099,0.11231807889958581,0.10533363904566646,0.10619282674488104,0.10702821409582597,0.1084718197181697],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100],\"y\":[0.9043373805664253,0.9043373805664253,0.2098351738665903,0.2098351738665903,0.2098351738665903,0.2098351738665903,0.2098351738665903,0.2098351738665903,0.2098351738665903,0.2098351738665903,0.2098351738665903,0.193150764129994,0.193150764129994,0.193150764129994,0.193150764129994,0.1736515460128269,0.1736515460128269,0.1736515460128269,0.1736515460128269,0.1736515460128269,0.1736515460128269,0.1736515460128269,0.1736515460128269,0.1736515460128269,0.1736515460128269,0.1736515460128269,0.1736515460128269,0.1736515460128269,0.1736515460128269,0.11977260347734363,0.11977260347734363,0.11977260347734363,0.11977260347734363,0.11977260347734363,0.11977260347734363,0.11977260347734363,0.11977260347734363,0.11977260347734363,0.11977260347734363,0.11977260347734363,0.11977260347734363,0.11977260347734363,0.11977260347734363,0.11977260347734363,0.11977260347734363,0.11977260347734363,0.11977260347734363,0.11977260347734363,0.11977260347734363,0.11977260347734363,0.11977260347734363,0.11977260347734363,0.11977260347734363,0.11977260347734363,0.11977260347734363,0.11977260347734363,0.11977260347734363,0.11977260347734363,0.11977260347734363,0.11977260347734363,0.11977260347734363,0.11977260347734363,0.11977260347734363,0.11977260347734363,0.11977260347734363,0.11977260347734363,0.11977260347734363,0.11977260347734363,0.10950503008146036,0.10814355929327969,0.09946178918358692,0.09946178918358692,0.09946178918358692,0.09946178918358692,0.09946178918358692,0.09946178918358692,0.09946178918358692,0.09946178918358692,0.09946178918358692,0.09946178918358692,0.0973087496787227,0.0973087496787227,0.0973087496787227,0.0973087496787227,0.0973087496787227,0.0973087496787227,0.0973087496787227,0.0973087496787227,0.0973087496787227,0.0973087496787227,0.0973087496787227,0.0973087496787227,0.0973087496787227,0.0973087496787227,0.0973087496787227,0.0973087496787227,0.0973087496787227,0.0973087496787227,0.0973087496787227,0.0973087496787227,0.0973087496787227],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#cccccc\"},\"mode\":\"markers\",\"name\":\"Infeasible Trial\",\"showlegend\":false,\"x\":[],\"y\":[],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermap\":[{\"type\":\"scattermap\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('306364cd-ac17-43dc-849c-e8a63d6a1043');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-3.1.0.min.js\" integrity=\"sha256-Ei4740bWZhaUTQuD6q9yQlgVCMPBz6CZWhevDYPv93A=\" crossorigin=\"anonymous\"></script>                <div id=\"2fbdc7d8-5bef-4eb8-adc3-65d03afad9fe\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById(\"2fbdc7d8-5bef-4eb8-adc3-65d03afad9fe\")) {                    Plotly.newPlot(                        \"2fbdc7d8-5bef-4eb8-adc3-65d03afad9fe\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"spect_embedding_dim (IntDistribution): 0.0028123221754135556\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"n_encoder_layers (IntDistribution): 0.013599260623097147\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"dropout_rate (FloatDistribution): 0.06257527577792629\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"categorical_loss_weight (FloatDistribution): 0.1689718462170371\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"n_hidden_neurons (IntDistribution): 0.2064875438628865\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"learning_rate (FloatDistribution): 0.5455537513436394\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"],\"name\":\"Objective Value\",\"orientation\":\"h\",\"text\":[\"\\u003c0.01\",\"0.01\",\"0.06\",\"0.17\",\"0.21\",\"0.55\"],\"textposition\":\"outside\",\"x\":[0.0028123221754135556,0.013599260623097147,0.06257527577792629,0.1689718462170371,0.2064875438628865,0.5455537513436394],\"y\":[\"spect_embedding_dim\",\"n_encoder_layers\",\"dropout_rate\",\"categorical_loss_weight\",\"n_hidden_neurons\",\"learning_rate\"],\"type\":\"bar\"}],                        {\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Hyperparameter Importance\"}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermap\":[{\"type\":\"scattermap\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('2fbdc7d8-5bef-4eb8-adc3-65d03afad9fe');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-3.1.0.min.js\" integrity=\"sha256-Ei4740bWZhaUTQuD6q9yQlgVCMPBz6CZWhevDYPv93A=\" crossorigin=\"anonymous\"></script>                <div id=\"3172a656-124c-4c15-9b9f-d02262c05ab9\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById(\"3172a656-124c-4c15-9b9f-d02262c05ab9\")) {                    Plotly.newPlot(                        \"3172a656-124c-4c15-9b9f-d02262c05ab9\",                        [{\"dimensions\":[{\"label\":\"Objective Value\",\"range\":[0.0973087496787227,2.239831152054742],\"values\":[0.9043373805664253,2.039987219667831,0.2098351738665903,0.2276665460823976,2.239831152054742,0.193150764129994,0.1736515460128269,0.11977260347734363,0.1438849911950219,0.1349963416033257,0.14696664090714626,0.13620597945521082,0.12541768039445136,0.1248980195537581,0.133001663817552,0.13364940535514475,0.13269867791879375,0.13177704688295763,0.10950503008146036,0.10814355929327969,0.09946178918358692,0.10505637770823081,0.1098959349312528,0.10926721508710173,0.09955605338753261,0.0973087496787227,0.11824671927210037,0.109504919999648,0.11309998444284099,0.11231807889958581,0.10533363904566646,0.10619282674488104,0.10702821409582597,0.1084718197181697]},{\"label\":\"categorical_loss_...\",\"range\":[-0.9989914793563075,-0.6280048876175355],\"ticktext\":[\"0.1\",\"0.236\"],\"tickvals\":[-0.9989914793563075,-0.6280048876175355],\"values\":[-0.6845316392396084,-0.6954831102245835,-0.9699658796446848,-0.7975913347863997,-0.6280048876175355,-0.9392060343366068,-0.897405469715968,-0.9581771787746074,-0.9186986423635449,-0.9041085792513046,-0.8887234906462953,-0.8771702039749252,-0.9674558254677063,-0.9673208362638642,-0.9673038848547927,-0.9460396195293299,-0.9400736218790696,-0.9041318512363921,-0.9887002990601162,-0.980477734901577,-0.9989914793563075,-0.9909551694374644,-0.9911391498320533,-0.9825464713154988,-0.983781873914703,-0.9872911179013326,-0.9985009470725916,-0.9761005386055268,-0.9491893741478367,-0.9309011234406503,-0.9684313229945881,-0.9692452736860222,-0.9713851879350583,-0.9706734326739158]},{\"label\":\"dropout_rate\",\"range\":[0.004781582174227354,0.1426949844529262],\"values\":[0.03401373151971999,0.04419463216540411,0.12130409812227555,0.09431504765480105,0.1426949844529262,0.09483231218789095,0.06797518338885773,0.025934823909675032,0.02852510846603047,0.031096782864231384,0.02956586341536925,0.028317478707015717,0.02139424594050398,0.022535215464340112,0.035579286793421386,0.015952321981684968,0.004781582174227354,0.011342090470809755,0.007614143097237321,0.008645941459332838,0.008033195534361005,0.012299396112653058,0.011464507164591006,0.02411874804818463,0.01462345683191355,0.005803352612374085,0.007039412188792444,0.007695968447295985,0.016894600762241446,0.008906610383051393,0.008895671719285132,0.008958677508601718,0.018291674591159473,0.026066678520000136]},{\"label\":\"learning_rate\",\"range\":[-3.49974296332695,-1.3175901916138375],\"ticktext\":[\"0.000316\",\"0.001\",\"0.01\",\"0.0481\"],\"tickvals\":[-3.49974296332695,-3,-2,-1.3175901916138375],\"values\":[-2.0498646922464987,-1.8597088038552951,-2.9115166778625645,-3.3410152258090924,-1.3175901916138375,-3.0936494056651576,-3.49974296332695,-2.9763766432053282,-3.219342954276252,-3.246111824997842,-3.3390400069648205,-3.2502588690650356,-3.193390519932204,-3.1552912488936826,-3.412124556880921,-3.3982614420406034,-3.4255928693374007,-3.124249937080674,-3.1146958735993353,-3.113613004179383,-2.9149785201280647,-3.1136817722198287,-3.1378758612426783,-2.9312231551976713,-2.9522929758151113,-2.8105510170947916,-2.4578433950147534,-2.607661482860658,-2.8170240829354563,-2.962878355831776,-2.9619927417201524,-2.7509548897139715,-2.9970324094612035,-2.9557556248838432]},{\"label\":\"n_encoder_layers\",\"range\":[4,5],\"values\":[5,4,5,5,5,5,5,5,5,5,5,5,5,5,5,5,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4]},{\"label\":\"n_hidden_neurons\",\"range\":[176,320],\"values\":[320,288,192,256,176,208,192,192,208,208,240,288,224,224,224,256,256,240,256,240,240,272,272,272,272,272,272,272,256,256,256,272,256,272]},{\"label\":\"spect_embedding_dim\",\"range\":[49,96],\"values\":[74,93,49,94,50,61,57,59,53,54,53,53,53,63,58,61,61,56,57,57,56,56,56,56,59,56,96,52,50,54,52,54,54,49]}],\"labelangle\":30,\"labelside\":\"bottom\",\"line\":{\"color\":[0.9043373805664253,2.039987219667831,0.2098351738665903,0.2276665460823976,2.239831152054742,0.193150764129994,0.1736515460128269,0.11977260347734363,0.1438849911950219,0.1349963416033257,0.14696664090714626,0.13620597945521082,0.12541768039445136,0.1248980195537581,0.133001663817552,0.13364940535514475,0.13269867791879375,0.13177704688295763,0.10950503008146036,0.10814355929327969,0.09946178918358692,0.10505637770823081,0.1098959349312528,0.10926721508710173,0.09955605338753261,0.0973087496787227,0.11824671927210037,0.109504919999648,0.11309998444284099,0.11231807889958581,0.10533363904566646,0.10619282674488104,0.10702821409582597,0.1084718197181697],\"colorbar\":{\"title\":{\"text\":\"Objective Value\"}},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"reversescale\":true,\"showscale\":true},\"type\":\"parcoords\"}],                        {\"title\":{\"text\":\"Parallel Coordinate Plot\"},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermap\":[{\"type\":\"scattermap\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('3172a656-124c-4c15-9b9f-d02262c05ab9');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig_1 = optuna.visualization.plot_optimization_history(study)\n",
        "fig_1.write_image(f'/content/drive/MyDrive/Plots/{study_name}_history.png')\n",
        "show(fig_1)\n",
        "fig_2 = optuna.visualization.plot_param_importances(study)\n",
        "fig_2.write_image(f'/content/drive/MyDrive/Plots/{study_name}_importances.png')\n",
        "show(fig_2)\n",
        "fig_3 = optuna.visualization.plot_parallel_coordinate(study)\n",
        "fig_3.write_image(f'/content/drive/MyDrive/Plots/{study_name}_parallel.png')\n",
        "show(fig_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSyCxpa7gOn3",
        "outputId": "1e5a3dd0-bd34-43d6-9666-5cff6501e4f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best study trial: 80\n",
            "Best validation loss: 0.0973087496787227\n",
            "Best hyperparameters found by Optuna: {'learning_rate': 0.0015468527826189955, 'dropout_rate': 0.005803352612374085, 'spect_embedding_dim': 56, 'n_encoder_layers': 4, 'n_hidden_neurons': 272, 'categorical_loss_weight': 0.1029695659605807}\n",
            "Best model loaded from '/content/drive/MyDrive/Checkpoints/AE_StellarParams_Latent_Wide_r3_trial_80_best.pth'\n",
            "\n",
            "Generating 3D coordinates for all stars.\n"
          ]
        }
      ],
      "source": [
        "# Get the best trial's parameters and value\n",
        "best_params = study.best_trial.params\n",
        "best_loss = study.best_trial.value\n",
        "best_trial = study.best_trial.number\n",
        "best_weights_url = f'/content/drive/MyDrive/Checkpoints/{study_name}_trial_{best_trial}_best.pth'\n",
        "best_weights = torch.load(best_weights_url, map_location=torch.device('cpu'))['model_state_dict']\n",
        "print(f'\\nBest study trial:', best_trial)\n",
        "print(f\"Best validation loss: {best_loss}\")\n",
        "print(f'Best hyperparameters found by Optuna:', best_params)\n",
        "\n",
        "# 2. Re-instantiate and Train the Best Model\n",
        "# We create a new model with the best parameters found by Optuna\n",
        "best_model = Autoencoder(\n",
        "             num_numerical_features=2,\n",
        "             num_spect_types=NUM_SPECT_TYPES,\n",
        "             spect_embedding_dim=best_params['spect_embedding_dim'],\n",
        "             n_encoder_layers=best_params['n_encoder_layers'],\n",
        "             n_hidden_neurons=best_params['n_hidden_neurons'],\n",
        "             dropout_rate=best_params['dropout_rate'])\n",
        "\n",
        "# Load the best model weights that were saved during the tuning process\n",
        "best_model.load_state_dict(best_weights)\n",
        "\n",
        "# The best model is already trained. No need to re-train.\n",
        "print(f\"Best model loaded from '{best_weights_url}'\")\n",
        "\n",
        "# 3. Generate 3D Coordinates for ALL Stars and Export to JSON\n",
        "# This is a crucial step to get the full star map, not just the validation set.\n",
        "print(\"\\nGenerating 3D coordinates for all stars.\")\n",
        "best_model.eval() # Set model to evaluation mode\n",
        "\n",
        "# First, get the combined full dataset (numerical + categorical)\n",
        "# from the original pre-processing step before the train/val split.\n",
        "# Re-create the full tensor datasets for a clean, deterministic output.\n",
        "scaled_numerical_features = scaler.fit_transform(df_filtered[['absmag', 'ci']])\n",
        "spect_encoded, _ = pd.factorize(df_filtered['spect'])\n",
        "\n",
        "full_dataset = TensorDataset(\n",
        "    torch.tensor(scaled_numerical_features, dtype=torch.float32),\n",
        "    torch.tensor(spect_encoded, dtype=torch.long))\n",
        "full_dataloader = DataLoader(full_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "all_coords = []\n",
        "with torch.no_grad():\n",
        "    for x_num, x_cat in full_dataloader:\n",
        "        coords, _, _ = best_model(x_num, x_cat)\n",
        "        all_coords.extend(coords.numpy().tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "tMKSYVo0CU-0"
      },
      "outputs": [],
      "source": [
        "def process_spectral_type(spect_string):\n",
        "    \"\"\"\n",
        "    Cleans and simplifies the spectral type string for visualization.\n",
        "\n",
        "    Args:\n",
        "        spect_string (str): The raw spectral type string.\n",
        "\n",
        "    Returns:\n",
        "        str: The processed spectral type string (e.g., 'G2').\n",
        "    \"\"\"\n",
        "    if pd.isna(spect_string):\n",
        "        return 'UNKNOWN'\n",
        "\n",
        "    spect_string = spect_string.upper().strip()\n",
        "\n",
        "    # Handle stars with multiple values (e.g., 'F3/F5V') by taking the first one\n",
        "    if '/' in spect_string:\n",
        "        spect_string = spect_string.split('/')[0]\n",
        "\n",
        "    # Take the first two characters.\n",
        "    simplified = spect_string[:2]\n",
        "\n",
        "    # Check if the second character is not a digit.\n",
        "    if len(simplified) < 2 or not simplified[1].isdigit():\n",
        "        # Assign a default of '5' for stars with no number (e.g., 'M', 'K', 'O')\n",
        "        simplified = simplified[0] + '5'\n",
        "\n",
        "    return simplified"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "SV-y-rQPZp0A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e0a915d-59f6-45bd-9ea7-59c8aae00eda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Essential star data saved to '/content/drive/MyDrive/Data/AE_StellarParams_Latent_Wide_r3_front.csv.gz'\n"
          ]
        }
      ],
      "source": [
        "def export_star_data_to_csv_gz(df_filtered, all_coords, output_path):\n",
        "    \"\"\"\n",
        "    Combines filtered star data with latent space coordinates and exports it\n",
        "    to a compressed CSV file.\n",
        "\n",
        "    This function removes unnecessary fields and includes only the data\n",
        "    required for the front-end visualization, resulting in a significantly\n",
        "    smaller and more efficient file.\n",
        "\n",
        "    Args:\n",
        "        df_filtered (pd.DataFrame): DataFrame containing filtered star data\n",
        "                                     (e.g., from the HYG database).\n",
        "        all_coords (list of lists): The latent space coordinates for each star.\n",
        "        output_path (str): The full path to save the gzipped CSV file.\n",
        "    \"\"\"\n",
        "    # 1. Create a DataFrame for the latent space coordinates\n",
        "    latent_df = pd.DataFrame(all_coords, columns=['latent_x', 'latent_y', 'latent_z'])\n",
        "\n",
        "    # Reset index of the filtered DataFrame for a clean merge\n",
        "    df_filtered = df_filtered.reset_index(drop=True)\n",
        "\n",
        "    # 2. Combine the original star data with the new latent space data\n",
        "    combined_df = pd.concat([df_filtered, latent_df], axis=1)\n",
        "\n",
        "    # 3. Process the 'spect' column using the new function\n",
        "    combined_df['spect'] = combined_df['spect'].apply(process_spectral_type)\n",
        "\n",
        "    # 4. Select and reorder only the essential columns\n",
        "    essential_df = combined_df[[\n",
        "        'id',\n",
        "        'latent_x',\n",
        "        'latent_y',\n",
        "        'latent_z',\n",
        "        'x',\n",
        "        'y',\n",
        "        'z',\n",
        "        'absmag',\n",
        "        'spect'\n",
        "    ]]\n",
        "\n",
        "    # 5. Round the floating-point numbers to reduce file size\n",
        "    essential_df = essential_df.round({\n",
        "        'latent_x': 4,\n",
        "        'latent_y': 4,\n",
        "        'latent_z': 4,\n",
        "        'x': 4,\n",
        "        'y': 4,\n",
        "        'z': 4,\n",
        "        'absmag': 4\n",
        "    })\n",
        "\n",
        "    # 6. Save the DataFrame directly to a gzipped CSV file\n",
        "    essential_df.to_csv(output_path, index=False, compression='gzip')\n",
        "\n",
        "    print(f\"Essential star data saved to '{output_path}'\")\n",
        "\n",
        "export_star_data_to_csv_gz(df_filtered, all_coords, f'/content/drive/MyDrive/Data/{study_name}_front.csv.gz')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}